



import os
import torch
from tqdm import tqdm

# ---------- utility functions ----------
def ensure_dir(path):
    os.makedirs(path, exist_ok=True)

def pad_or_truncate_x(x: torch.Tensor, target_dim: int):
    """Make sure node feature dim == target_dim"""
    n, d = x.shape
    if d == target_dim:
        return x
    if d > target_dim:
        return x[:, :target_dim]
    # pad with zeros
    pad = torch.zeros((n, target_dim - d), dtype=x.dtype)
    return torch.cat([x, pad], dim=1)

# ---------- a toy encoder you should replace with real featurization ----------
def encode_node_features_from_scan(node_info_list, target_dim=11):
    """
    node_info_list: list of dicts, one per node, e.g. {'os': 'linux', 'open_ports': [22,80], 'has_cve': True}
    Returns: torch.Tensor shape [num_nodes, target_dim]
    """
    # Simple example: numeric features only (replace with richer encoding)
    feats = []
    for info in node_info_list:
        os_linux = 1.0 if info.get("os", "").lower() == "linux" else 0.0
        open_ports_count = float(len(info.get("open_ports", [])))
        cve_count = float(len(info.get("cves", []))) if info.get("cves") else 0.0
        last_seen_age = float(info.get("last_seen_days", 0))
        # pack into vector (this is a toy vector; expand and normalize properly)
        vec = [os_linux, open_ports_count, cve_count, last_seen_age]
        # pad to target_dim
        v = torch.tensor(vec, dtype=torch.float).unsqueeze(0)
        v = pad_or_truncate_x(v, target_dim)
        feats.append(v.squeeze(0))
    return torch.stack(feats, dim=0)

# ---------- builder for network graphs ----------
def build_graph_cache_network(raw_network_scans, out_dir, target_feat_dim=11):
    """
    raw_network_scans: iterable of items, each item describes one graph
      e.g. {'graph_id': 'scan_123', 'nodes': [...], 'edges': [(i,j),...], 'label': 0}
    Saves one file per graph: out_dir/graph_{graph_id}.pt containing {'data': Data(...), 'meta': {...}}
    """
    ensure_dir(out_dir)
    for item in tqdm(raw_network_scans, desc="Building network caches"):
        node_infos = item["nodes"]                # list of dicts
        x = encode_node_features_from_scan(node_infos, target_dim=target_feat_dim)  # [N, D]
        edge_index = torch.tensor(item.get("edges", []), dtype=torch.long).t().contiguous()
        # if there are no edges, create empty edge_index
        if edge_index.numel() == 0:
            edge_index = torch.empty((2,0), dtype=torch.long)
        y = torch.tensor([item.get("label", 0)], dtype=torch.long)   # graph label
        data = Data(x=x, edge_index=edge_index, y=y)
        meta = {"graph_id": item.get("graph_id")}
        fname = os.path.join(out_dir, f"network_{meta['graph_id']}.pt")
        torch.save({"data": data, "meta": meta}, fname)

# ---------- builder for vulnerability graphs ----------
def build_graph_cache_vuln(raw_vuln_items, out_dir, target_feat_dim=11):
    """
    raw_vuln_items: iterable of items, each representing a vulnerability surface graph
      e.g. {'id':'v_1', 'nodes':[...], 'edges':[(i,j)...], 'label':1}
    Similar to network builder but you can add CVE-specific node encodings.
    """
    ensure_dir(out_dir)
    for item in tqdm(raw_vuln_items, desc="Building vuln caches"):
        node_infos = item["nodes"]
        x = encode_node_features_from_scan(node_infos, target_dim=target_feat_dim)
        edge_index = torch.tensor(item.get("edges", []), dtype=torch.long).t().contiguous()
        if edge_index.numel() == 0:
            edge_index = torch.empty((2,0), dtype=torch.long)
        y = torch.tensor([item.get("label", 0)], dtype=torch.long)
        data = Data(x=x, edge_index=edge_index, y=y)
        meta = {"vuln_id": item.get("id")}
        fname = os.path.join(out_dir, f"vuln_{meta['vuln_id']}.pt")
        torch.save({"data": data, "meta": meta}, fname)


from xml.etree import ElementTree as ET
import torch
from torch_geometric.data import Data

def parse_nmap_xml(file_path):
    tree = ET.parse(file_path)
    root = tree.getroot()
    graphs = []

    for host in root.findall("host"):
        if host.find("status").attrib.get("state") != "up":
            continue

        ip = host.find("address").attrib["addr"]
        os_guess = host.findtext(".//osmatch[@name]") or "unknown"

        nodes, edges = [], []
        features = []

        # node 0 = host itself
        nodes.append(ip)
        os_linux = 1.0 if "linux" in os_guess.lower() else 0.0
        features.append([os_linux, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])  # shape 11

        # service nodes
        for port in host.findall(".//port"):
            portid = int(port.attrib["portid"])
            service = port.find("service")
            sname = service.attrib.get("name", "unknown")
            nodes.append(f"{ip}:{portid}/{sname}")
            is_service = 1.0
            features.append([0, is_service, portid / 65535, 0, 0, 0, 0, 0, 0, 0, 0])
            edges.append((0, len(nodes) - 1))
            edges.append((len(nodes) - 1, 0))  # bidirectional

        x = torch.tensor(features, dtype=torch.float)
        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        y = torch.tensor([1], dtype=torch.long)  # placeholder label

        graphs.append(Data(x=x, edge_index=edge_index, y=y))
    return graphs

# from pymongo import MongoClient
# from pprint import pprint
#
# class PricingManager:
#     def __init__(self, db):
#         self.db = db
#         self.telemetry_logs = db.get_collection("telemetry_logs")
#
#         # Default pricing parameters
#         self.cpu_cost_per_second = 0.00001
#         self.ai_inference_cost = 0.002
#         self.storage_cost_per_gb_month = 0.01
#         self.retention_days = 30
#         self.markup_factor = 1.25
#         self.flat_fee = 0.05
#
#     def get_logs(self, filter_query=None):
#         """Fetch telemetry logs from MongoDB"""
#         if filter_query is None:
#             filter_query = {}
#         logs = list(self.telemetry_logs.find(filter_query))
#         return logs
#
#     def compute_price(self, log):
#         """Compute the price based on telemetry data"""
#         cpu_seconds = log.get("cpu_seconds", 0)
#         storage_size_mb = log.get("storage_size_mb", 0)
#         ai_used = "model_name" in log and log["model_name"].startswith("ai_")
#
#         compute_cost = cpu_seconds * self.cpu_cost_per_second
#         inference_cost = self.ai_inference_cost if ai_used else 0
#         storage_cost = (
#                 (storage_size_mb / 1024)
#                 * self.storage_cost_per_gb_month
#                 * (self.retention_days / 30)
#         )
#
#         total_cost = compute_cost + inference_cost + storage_cost
#         price = total_cost * self.markup_factor + self.flat_fee
#
#         return {
#             "task_id": log.get("task_id"),
#             "user_id": log.get("user_id"),
#             "model_name": log.get("model_name"),
#             "cpu_seconds": cpu_seconds,
#             "storage_size_mb": storage_size_mb,
#             "ai_used": ai_used,
#             "cost_details": {
#                 "compute_cost": round(compute_cost, 6),
#                 "inference_cost": round(inference_cost, 6),
#                 "storage_cost": round(storage_cost, 6),
#                 "total_cost": round(total_cost, 6),
#             },
#             "final_price": round(price, 6),
#         }
#
#     def get_all_pricing(self):
#         """Fetch all logs and compute pricing for each"""
#         logs = self.get_logs()
#         return [self.compute_price(log) for log in logs]
#
#
# def main():
#     try:
#         client = MongoClient("mongodb+srv://kamsteph:Test1234@kaliacluster.mzupz.mongodb.net/?retryWrites=true&w=majority&appName=kaliaCluster", serverSelectionTimeoutMS=2000)
#         db = client["ai_pentest_dbs"]
#         # Test the connection
#         client.server_info()
#         print("‚úÖ Connected to MongoDB.")
#     except Exception as e:
#         print(f"‚ö†Ô∏è Could not connect to MongoDB: {e}")
#         # Fallback mock DB simulation
#         class MockDB:
#             def get_collection(self, name):
#                 return self
#             def find(self, _=None):
#                 return [
#                     {
#                         "task_id": None,
#                         "user_id": "unknown",
#                         "event": "scan_complete",
#                         "progress": 100,
#                         "threats_found": 0,
#                         "risk_level": "Unknown",
#                         "duration": 2.93,
#                         "summary": "No summary available.",
#                         "model_name": "ai_pentest_orchestrator_v1",
#                         "runtime_seconds": 2.93,
#                         "cpu_seconds": 0.172,
#                         "ram_used_mb": 40.812,
#                         "timestamp": "2025-10-05 12:27:05",
#                         "storage_size_mb": 0.0001,
#                         "cost_estimate_usd": 0.0005
#                     },
#                     {
#                         "task_id": "task_002",
#                         "user_id": "user123",
#                         "event": "scan_complete",
#                         "cpu_seconds": 1.0,
#                         "storage_size_mb": 2.5,
#                         "model_name": "manual_scan_v2"
#                     }
#                 ]
#         db = MockDB()
#
#     pricing_manager = PricingManager(db)
#     results = pricing_manager.get_all_pricing()
#
#     print("\nüìä Pricing Results:")
#     for i, result in enumerate(results, 1):
#         print(f"\n--- Result #{i} ---")
#         pprint(result)
#
#
# if __name__ == "__main__":
#     from pymongo import MongoClient
#
#     try:
#         client = MongoClient("mongodb+srv://kamsteph:Test1234@kaliacluster.mzupz.mongodb.net/?retryWrites=true&w=majority&appName=kaliaCluster")
#         db = client["ai_pentest_dbs"]
#         print("‚úÖ Connected to MongoDB.\n")
#     except Exception as e:
#         print(f"‚ùå Failed to connect to MongoDB: {e}")
#         exit(1)
#
#     pricing_manager = PricingManager(db)
#     results = pricing_manager.get_all_pricing()
#
#     print("üìä Pricing Results:\n")
#
#     # --- Display detailed results ---
#     for idx, res in enumerate(results, start=1):
#         print(f"--- Result #{idx} ---")
#         print(res)
#         print()
#
#     # --- Display clear summary outside the full results ---
#     print("üí∞ Price Summary:\n")
#     total_price = 0
#     for idx, res in enumerate(results, start=1):
#         price = res["final_price"]
#         total_price += price
#         task = res.get("task_id") or "no_task_id"
#         print(f"{idx}. Task ID: {task} ‚Üí ${price:.6f}")
#
#     avg_price = total_price / len(results) if results else 0
#     print(f"\nüìà Average Price: ${avg_price:.6f}")
#     print(f"üì¶ Total Sum: ${total_price:.6f}")
