# back_end/hyperparams.py
"""
Centralized hyperparameters for models, RL, and training.
Edit values here and document changes.
"""

# Device
DEVICE = "cuda"  # "cuda" or "cpu"

# ExploitationAgent / DQN
DQN = {
    "input_dim": 4,            # length of state-action vector passed to QNet
    "hidden": 64,              # hidden size of QNet
    "lr": 1e-3,                # optimizer learning rate
    "gamma": 0.99,             # discount factor (future reward importance)
    "buffer_size": 10000,      # in-memory replay buffer size
    "min_replay_size": 128,    # min experiences before learning starts
    "batch_size": 32,          # training batch size
    "target_update_freq": 1000 # steps between target network updates
}

# GNN encoders (VulnerabilityManagerGNN, NetworkManagerGNN)
GNN = {
    "in_channels": 11,   # node feature dimension
    "hidden": 64,        # hidden units in GNN
    "num_classes": 2,    # output classes / logits
    "dropout": 0.3
}

# Training / sandbox
TRAIN = {
    "safe_payload": "generic/safe",
    "training_mode": True,   # switch to False for aggressive/live actions
    "max_steps_per_target": 5 # how many actions to attempt before giving up
}

# Reward shaping (scale rewards for different outcomes)
REWARD = {
    "success_base": 1.0,     # base reward for a successful exploit
    "partial_success": 0.5,  # reward for secondary evidence (e.g., db interaction)
    "failure": -0.3          # penalty for failed attempt
}

#FOR THE VULNERABILITY AGENT
LHF_WEIGHTS = {
    "default_creds":  -0.35,
    "shared_creds":   -0.25,
    "admin_all_users":-0.20,
    "public_exploit": -0.45
}
SCORE_WEIGHTS = {
    "lhf": 0.6,
    "services": 0.25,
    "cvss": 0.15
}
LEVEL_THRESHOLDS = {"level1": 0.3, "level2": 0.7}
ENABLE_PREEXP_ON_L1 = False  # toggle

# Known default username/password patterns (small starter list â€” extend)
KNOWN_DEFAULT_CREDENTIALS = [
    ("admin", "admin"), ("root", "root"), ("admin", "password"),
    ("admin", ""), ("root", ""), ("user", "user"), ("guest", "guest")
]

# Patterns indicating default config mention in banner or summary
DEFAULT_BANNER_PATTERNS = [
    r"default password", r"factory default", r"admin:admin", r"root:root",
    r"out of the box", r"initial password"
]
W_LHF, W_SERVICES, W_CVSS = 0.6, 0.25, 0.15


#FOR THE EXPLOIT SELECTOR CLUSTERED WITH THE EXP'S RL
# -----------------------------------------------------------------
# Selector / hint persistence hyperparameters
# -----------------------------------------------------------------
# How quickly learned hints decay (exponential): per-day decay factor (0.0-1.0).
# Lower = older observations lose influence faster. 1.0 = no decay.
HINT_DECAY_DAILY_FACTOR = 0.995

# Minimum number of observations before a hint is considered "trusted"
HINT_MIN_COUNT = 5

# Bayesian prior for success rate calculation (Beta prior)
# alpha = prior successes, beta = prior failures
# (alpha=1,beta=1 is uniform / weak prior)
HINT_BAYES_ALPHA = 1.0
HINT_BAYES_BETA = 1.0

# How to combine agent Q-value and selector hint when ranking:
# Combined_score = AGENT_WEIGHT * q_value + HINT_WEIGHT * hint_score
AGENT_WEIGHT = 0.8
HINT_WEIGHT = 0.2

#hard threshold for applying overlay
HINT_APPLY_MIN_CONFIDENCE = 0.6  # only use hint if its confidence >= this
