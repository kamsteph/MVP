"""
train_all_gnns.py

Unified trainer for:
  - NetworkManagerGNN
  - VulnerabilityManagerGNN
  - ExploitManagerGNN

Includes:
  - Loads labeled data from MongoDB
  - Automatic checkpoint saving
  - Evaluation metrics using utils.metrics
"""

import torch
import torch.nn as nn
from torch.optim import Adam
from torch_geometric.loader import DataLoader
from torch_geometric.data import Data

from Network_Pentest.network.Brain.gan_train import HoneynetGANTrainer
from back_end.database import DatabaseManager
from Network_Pentest.network.Brain.gnn_models import NetworkManagerGNN, VulnerabilityManagerGNN, ExploitManagerGNN
from Network_Pentest.network.utils.metrics import MetricsRecorder


import os
import random
import numpy as np
import torch

def set_global_seed(seed: int = 42, use_cuda: bool = False):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if use_cuda and torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        # makes some conv/cudnn deterministic but may slow down
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

# call early in training main:
set_global_seed(2025, use_cuda=torch.cuda.is_available())

# -------------------------------------------------------------------------
# Utility functions
# -------------------------------------------------------------------------

def train_epoch(model, loader, optimizer, criterion, device):
    """
    Trains one epoch on a batch loader.
    - model.train() enables dropout, BN updates
    - Each batch is moved to the selected device (CPU/GPU)
    """
    model.train()
    total_loss = 0
    for batch in loader:
        batch = batch.to(device)
        optimizer.zero_grad()

        # Pass batch through model
        out = model(batch.x, batch.edge_index, batch.batch)
        loss = criterion(out, batch.y.view(-1))  # flatten labels
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)


def eval_epoch(model, loader, device):
    """
    Evaluation step.
    Returns accuracy for classification models.
    """
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)
            out = model(batch.x, batch.edge_index, batch.batch)
            preds = out.argmax(dim=1)
            correct += (preds == batch.y.view(-1)).sum().item()
            total += batch.num_graphs
    return correct / total if total > 0 else 0.0


# -------------------------------------------------------------------------
# Trainer Class
# -------------------------------------------------------------------------
class UnifiedTrainer:
    """
    UnifiedTrainer handles the training of all three GNNs.
    - It can build datasets directly from MongoDB (standard_db / adb_collection)
    - It logs metrics to MongoDB using MetricsRecorder
    """

    def __init__(self, device="cpu"):
        self.device = torch.device(device)
        self.db = DatabaseManager()
        self.metrics = MetricsRecorder(db_logging=True)

    # ---------------------------------------------------------
    # 1. Load datasets from MongoDB
    # ---------------------------------------------------------
    def _load_dataset_from_db(self, collection_name, label_field="label"):
        """
        Pulls training samples from MongoDB.
        Expects that each record has:
           - 'nodes': list of node features (2D list)
           - 'edges': list of edges [[a,b], [b,a], ...]
           - 'label': graph label (int for classification, 0/1 for binary)
        Example:
          {
            "nodes": [[...],[...]],
            "edges": [[0,1],[1,2],[2,0]],
            "label": 1
          }
        """
        collection = getattr(self.db, collection_name)
        cursor = collection.find({"nodes": {"$exists": True}})
        data_list = []

        for doc in cursor:
            try:
                x = torch.tensor(doc["nodes"], dtype=torch.float)
                edge_index = torch.tensor(doc["edges"], dtype=torch.long).t().contiguous()
                y = torch.tensor([doc.get(label_field, 0)], dtype=torch.long)
                data = Data(x=x, edge_index=edge_index, y=y)
                data_list.append(data)
            except Exception as e:
                print(f"[WARN] Skipped invalid doc: {e}")
                continue

        return data_list

    # ---------------------------------------------------------
    # 2. Train each model
    # ---------------------------------------------------------
    def train_network_gnn(self, collection_name="standard_db", epochs=20):
        """
        Train the NetworkManagerGNN model.
        Uses graph-level labels (e.g. 0=delegate, 1=deeper_scan)
        """
        print("üöÄ Starting NetworkManagerGNN training...")
        dataset = self._load_dataset_from_db(collection_name)
        if not dataset:
            print("‚ùå No training data found in MongoDB!")
            return

        loader = DataLoader(dataset, batch_size=8, shuffle=True)
        model = NetworkManagerGNN(in_channels=11, hidden=64, num_classes=2).to(self.device)
        optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            loss = train_epoch(model, loader, optimizer, criterion, self.device)
            acc = eval_epoch(model, loader, self.device)
            print(f"[NetworkGNN] Epoch {epoch+1:03d} | Loss {loss:.4f} | Acc {acc:.4f}")
            self.metrics.classification_metrics([], [], phase="network_gnn")  # optional DB log

        torch.save(model.state_dict(), "network_gnn.pt")
        print("‚úÖ Saved network_gnn.pt")

    def train_vuln_gnn(self, collection_name="standard_db", epochs=20):
        """
        Train the VulnerabilityManagerGNN model.
        Graph-level classifier (e.g. 0=no_action, 1=investigate/exploit)
        """
        print("üöÄ Starting VulnerabilityManagerGNN training...")
        dataset = self._load_dataset_from_db(collection_name)
        if not dataset:
            print("‚ùå No training data found in MongoDB!")
            return

        loader = DataLoader(dataset, batch_size=8, shuffle=True)
        model = VulnerabilityManagerGNN(in_channels=11, hidden=64, num_classes=2).to(self.device)
        optimizer = Adam(model.parameters(), lr=1e-3)
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            loss = train_epoch(model, loader, optimizer, criterion, self.device)
            acc = eval_epoch(model, loader, self.device)
            print(f"[VulnGNN] Epoch {epoch+1:03d} | Loss {loss:.4f} | Acc {acc:.4f}")
            self.metrics.classification_metrics([], [], phase="vuln_gnn")  # optional DB log

        torch.save(model.state_dict(), "vuln_gnn.pt")
        print("‚úÖ Saved vuln_gnn.pt")

    def train_exploit_gnn(self, collection_name="standard_db", epochs=25):
        """
        Train the ExploitManagerGNN model.
        Node-level binary predictor (uses BCEWithLogitsLoss).
        """
        print("üöÄ Starting ExploitManagerGNN training...")
        dataset = self._load_dataset_from_db(collection_name)
        if not dataset:
            print("‚ùå No training data found in MongoDB!")
            return

        loader = DataLoader(dataset, batch_size=8, shuffle=True)
        model = ExploitManagerGNN(in_channels=6, hidden=48, heads=6).to(self.device)
        optimizer = Adam(model.parameters(), lr=5e-4)
        criterion = nn.BCEWithLogitsLoss()

        for epoch in range(epochs):
            model.train()
            total_loss = 0
            for batch in loader:
                batch = batch.to(self.device)
                optimizer.zero_grad()

                # FIXED: 'data' was undefined; should use the batch variable here
                out = model(batch.x, batch.edge_index)
                logits = out["success_logits"]

                # Convert labels to float for BCE loss
                labels = batch.y.float().view(-1)
                loss = criterion(logits, labels)

                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            avg_loss = total_loss / len(loader)
            print(f"[ExploitGNN] Epoch {epoch+1:03d} | Loss {avg_loss:.4f}")

        torch.save(model.state_dict(), "exploit_gnn.pt")
        print("‚úÖ Saved exploit_gnn.pt")

if __name__ == "__main__":
    trainer = UnifiedTrainer(device="cuda" if torch.cuda.is_available() else "cpu")

    # Normal GNN training
    trainer.train_network_gnn()
    trainer.train_vuln_gnn()
    trainer.train_exploit_gnn()

    # Optional GAN training mode
    enable_gan_training = True
    if enable_gan_training:
        gan_trainer = HoneynetGANTrainer(device=trainer.device)
        gan_trainer.train(epochs=100, batch_size=64)

