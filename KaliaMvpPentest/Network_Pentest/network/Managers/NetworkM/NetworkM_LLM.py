# file: Network_Pentest/network/Managers/network_manager_llm.py
import json
import logging
from copy import deepcopy
from datetime import datetime
from typing import List, Dict, Any

import torch
from jsonschema import validate, ValidationError

from Network_Pentest.network.Managers.ptt_files.LLM_OUTPUT import LLM_PLAN_SCHEMA
from Network_Pentest.network.Managers.NetworkM.NetworkM_GNN import NetworkManager
from Network_Pentest.network.Managers.ptt_files.network_llm_schema import OpenAILLMClient
from back_end.database import DatabaseManager
from back_end.event_bus import EventBus



from Network_Pentest.network.Managers.ptt_files.PTT import INPT_PTT_TEMPLATE

logger = logging.getLogger("NETWORK_MGR_LLM")
logger.setLevel(logging.INFO)


class NetworkManagerLLM:
    """
    High-level coordinator for INPT (internal network pentest) in the network domain.

    - Uses NetworkManager (GNN) for graph-level decisions (delegate vs deeper_scan).
    - Uses LLM for:
        * enforcing the INPT PTT (Phase 1..4)
        * deciding which module should act next (recon / VAI / EXP / DOCS)
        * detecting cross-domain hints & alerting the Pentest Orchestrator.
    """

    def __init__(
            self,
            base_manager: NetworkManager,
            bus: EventBus,
            db: DatabaseManager,
            llm_client: OpenAILLMClient = None,
            gnn_confidence_threshold: float = 0.15,
            llm_override_confidence: float = 0.75,
    ):
        self.base_manager = base_manager
        self.bus = bus
        self.db = db
        self.llm = llm_client or OpenAILLMClient()
        self.gnn_confidence_threshold = gnn_confidence_threshold
        self.llm_override_confidence = llm_override_confidence
        self.llm_logs = self.db.standard_db
        self.llm_logs.create_index("task_id")
        self.llm_logs.create_index("kind")


# In-memory PTT state per task
        self._ptt_state: Dict[str, Dict[str, Any]] = {}

    # ------------------------------------------------------------------
    # PTT state helpers
    # ------------------------------------------------------------------
    def _get_or_init_ptt_state(self, task_id: str) -> Dict[str, Any]:
        if task_id not in self._ptt_state:
            self._ptt_state[task_id] = deepcopy(INPT_PTT_TEMPLATE)
        return self._ptt_state[task_id]

    def _update_ptt_state(self, task_id: str, new_state: Dict[str, Any], note: str = ""):
        st = self._get_or_init_ptt_state(task_id)
        st["current_phase"] = new_state.get("current_phase", st["current_phase"])
        st["current_step"] = new_state.get("current_step", st["current_step"])
        st["completed_steps"] = list(
            dict.fromkeys(st.get("completed_steps", []) + new_state.get("completed_steps", []))
        )
        if note:
            st.setdefault("history", []).append(
                {
                    "phase": st["current_phase"],
                    "step": st["current_step"],
                    "note": note,
                }
            )

    # ------------------------------------------------------------------
    # Context building for LLM
    # ------------------------------------------------------------------
    def _build_scan_summary(self, scan_results: List[Dict[str, Any]], max_hosts: int = 12) -> str:
        """

        Small JSON summary of scan results for the LLM:
        top hosts by vulns/services and some cross-domain hints.
        """
        # sort by (#vulns, #services) descending
        sorted_hosts = sorted(
            scan_results,
            key=lambda r: (
                len(r.get("vulnerabilities", []) or []),
                len(r.get("services", []) or []),
            ),
            reverse=True,
        )

        summary = []
        for r in sorted_hosts[:max_hosts]:
            services = r.get("services", []) or []
            vulns = r.get("vulnerabilities", []) or []
            service_names = [
                (s.get("name") or str(s.get("port"))) for s in services if (s.get("name") or s.get("port"))
            ]
            vuln_ids = [
                (v.get("cve") or v.get("id")) for v in vulns if (v.get("cve") or v.get("id"))
            ]

            # crude cross-domain hints: web, AD, cloud etc
            hints = []
            for sname in service_names:
                s_lower = str(sname).lower()
                if "http" in s_lower or "https" in s_lower:
                    hints.append("WEB_LIKELY")
                if "ldap" in s_lower or "kerberos" in s_lower or "msrpc" in s_lower:
                    hints.append("AD_LIKELY")
                if "s3" in s_lower or "azure" in s_lower:
                    hints.append("CLOUD_LIKELY")

            summary.append(
                {
                    "ip": r.get("ip"),
                    "alive": r.get("alive", True),
                    "risk": r.get("risk", "unknown"),
                    "num_services": len(services),
                    "num_vulns": len(vulns),
                    "services": service_names[:8],
                    "vulns": vuln_ids[:8],
                    "hints": list(set(hints)),
                }
            )
        return json.dumps(summary, indent=2)

    def _build_gnn_summary(self, probs_tensor: torch.Tensor, action: str) -> Dict[str, Any]:
        probs = probs_tensor.detach().cpu().tolist()
        if isinstance(probs, (float, int)):
            probs = [float(probs)]
        margin = 0.0
        if len(probs) >= 2:
            margin = abs(probs[0] - probs[1])
        return {
            "action": action,        # "delegate" or "deeper_scan"
            "probs": probs,
            "margin": margin,
        }

    # ------------------------------------------------------------------
    # LLM call
    # ------------------------------------------------------------------
    def _call_llm_for_plan(
            self,
            task_id: str,
            scan_results: List[Dict[str, Any]],
            gnn_summary: Dict[str, Any],
    ) -> Dict[str, Any]:
        ptt_state = self._get_or_init_ptt_state(task_id)

        # System prompt: INPT PTT enforcement + safety
        system_prompt = (
            "You are an internal network penetration test (INPT) coordinator. "
            "You ONLY control high-level methodology for the network domain.\n\n"
            "You MUST follow this PTT strictly:\n"
            "- Phase 1: Information gathering (P1A_HOST_DISCOVERY, P1B_ENUM_SERVICES, P1C_DISCOVER_SURFACES)\n"
            "- Phase 2: Focused penetration (P2A_COMPROMISE_LEVEL1, P2B_EXPLOIT_MISSING_PATCHES, P2C_RMI_ACCESS)\n"
            "- Phase 3: Post-exploitation & privilege escalation (P3A_ESTABLISH_REENTRY, P3B_HARVEST_CREDS, "
            "P3C_MOVE_LATERAL_LEVEL2, P3D_IDENT_PRIV_USERS, P3E_ELEVATE_DOMAIN_ADMIN)\n"
            "- Phase 4: Documentation (P4A_GATHER_EVIDENCE, P4B_LINEAR_NARRATIVES, P4C_FINAL_DELIVERABLE)\n\n"
            "Rules:\n"
            "- You NEVER run low-level commands yourself; you only output JSON with module actions.\n"
            "- You NEVER ask for destructive behavior that is out of scope.\n"
            "- You MUST keep phases ordered: finish core steps of P1 before heavy exploitation in P2; "
            "only move to P3/P4 when justified.\n"
            "- For cross-domain hints (e.g., AD, web), you only raise alerts; you do NOT execute AD/web attacks.\n"
            "- Output STRICT JSON, matching the provided schema. No explanations, no prose.\n"
        )

        user_prompt = (
            "CURRENT_PTT_STATE:\n"
            f"{json.dumps(ptt_state, indent=2)}\n\n"
            "GNN_DECISION:\n"
            f"{json.dumps(gnn_summary, indent=2)}\n\n"
            "SCAN_SUMMARY:\n"
            f"{self._build_scan_summary(scan_results)}\n\n"
            "TASK:\n"
            "- Decide the next phase/step within the INPT PTT.\n"
            "- Recommend a small list of high-level actions for modules: recon, vai, exp, docs.\n"
            "- If you see hints of AD or WEB, add cross_domain_alerts.\n"
            "- Set confidence between 0.0 and 1.0 based on how clear the next step is.\n"
        )

        text = self.llm.complete(system_prompt, user_prompt)

        try:
            parsed = json.loads(text)
        except Exception as e:
            logger.error("LLM returned non-JSON for task %s: %s", task_id, e)
            self.db.log_llm_interaction({
                "task_id": task_id,
                "kind": "network_mgr_llm",
                "prompt": user_prompt,
                "raw_response": text,
                "error": str(e),
            })
            raise RuntimeError("LLM returned invalid JSON (NetworkManagerLLM)")

        # validate schema
        try:
            validate(parsed, LLM_PLAN_SCHEMA)
        except ValidationError as ve:
            logger.error("LLM JSON validation failed for task %s: %s", task_id, ve)
            self.db.log_llm_interaction({
                "task_id": task_id,
                "kind": "network_mgr_llm",
                "prompt": user_prompt,
                "raw_response": parsed,
                "validation_error": str(ve),
            })
            raise

        # store for audit
        self.db.log_llm_interaction({
            "task_id": task_id,
            "kind": "network_mgr_llm",
            "prompt": user_prompt,
            "response": parsed,
        })
        return parsed

        def _dispatch_actions(
                self,
                task_id: str,
                actions: List[Dict[str, Any]],
                hints: Dict[str, Any]
        ):
            """
            Map high-level module actions to event bus tasks.
            We DO NOT run tools directly here.
            """
        for step in actions:
            module = step["module"]
            action_type = step["action_type"]
            targets = step.get("targets", [])
            notes = step.get("notes", "")

            if module == "recon" and action_type == "RUN_RECON_PHASE1":
                payload = {
                    "id": task_id,
                    "region": "network",
                    "action": "network_recon_scan",
                    "target": targets,
                    "hints": hints,
                    "note": notes,
                }
                logger.info("[NetworkManagerLLM] Emitting RECON task: %s", payload)
                self.bus.publish_task(payload)

            elif module == "vai" and action_type == "RUN_VAI_ANALYSIS":
                payload = {
                    "id": task_id,
                    "region": "network",
                    "action": "run_vai_analysis",
                    "target": targets,
                    "hints": hints,
                    "note": notes,
                }
                logger.info("[NetworkManagerLLM] Emitting VAI task: %s", payload)
                self.bus.publish_task(payload)

            #  UPDATED: simulation goes to honeynet / Firecracker, not direct prod
            elif module == "exp" and action_type == "RUN_EXPLOIT_SIMULATION":
                honeynet_payload = {
                    "id": task_id,
                    "task_id": task_id,
                    "region": "network",
                    "action": "deploy_honeynet",       # DeceptionLearning subscribes to this
                    "type": "network",
                    "targets": targets,                 # hosts we want to simulate on
                    "level_summary": hints.get("level_summary", {}),
                    "host_records": hints.get("host_records", []),
                    "note": notes,
                    # you can also pass scope/mode if useful
                    "scope": hints.get("scope"),
                    "mode": hints.get("mode", "live"),
                }
                logger.info("[NetworkManagerLLM] Emitting honeynet deploy task: %s", honeynet_payload)
                self.bus.publish_task(honeynet_payload)

            # production exploitation can still go via EXP directly
            elif module == "exp" and action_type == "RUN_EXPLOIT_PRODUCTION":
                payload = {
                    "id": task_id,
                    "region": "network",
                    "action": "run_exploit_stage",
                    "target": targets,
                    "mode": "production",
                    "hints": hints,
                    "note": notes,
                }
                logger.info("[NetworkManagerLLM] Emitting EXPLOIT (prod) task: %s", payload)
                self.bus.publish_task(payload)

            elif module == "docs" and action_type == "RUN_DOC_SUMMARY":
                payload = {
                    "id": task_id,
                    "region": "network",
                    "action": "run_doc_update",
                    "target": targets,
                    "hints": hints,
                    "note": notes,
                }
                logger.info("[NetworkManagerLLM] Emitting DOC task: %s", payload)
                self.bus.publish_task(payload)

            else:
                logger.warning("[NetworkManagerLLM] Unknown module/action_type: %s/%s", module, action_type)

    # ------------------------------------------------------------------
    # Dispatch actions to the rest of the system
    # ------------------------------------------------------------------
    # def _dispatch_actions(
    #         self,
    #         task_id: str,
    #         actions: List[Dict[str, Any]],
    #         hints: Dict[str, Any]
    # ):
    #     """
    #     Map high-level module actions to event bus tasks.
    #     We DO NOT run tools directly here.
    #     """
    #     for step in actions:
    #         module = step["module"]
    #         action_type = step["action_type"]
    #         targets = step.get("targets", [])
    #         notes = step.get("notes", "")
    #
    #         if module == "recon" and action_type == "RUN_RECON_PHASE1":
    #             # Use ReconManager via bus; it already listens to 'network_recon_scan'
    #             payload = {
    #                 "id": task_id,
    #                 "region": "network",
    #                 "action": "network_recon_scan",
    #                 "target": targets,
    #                 "hints": hints,
    #                 "note": notes,
    #             }
    #             logger.info("[NetworkManagerLLM] Emitting RECON task: %s", payload)
    #             self.bus.publish_task(payload)
    #
    #         elif module == "vai" and action_type == "RUN_VAI_ANALYSIS":
    #             payload = {
    #                 "id": task_id,
    #                 "region": "network",
    #                 "action": "run_vai_analysis",
    #                 "target": targets,
    #                 "hints": hints,
    #                 "note": notes,
    #             }
    #             logger.info("[NetworkManagerLLM] Emitting VAI task: %s", payload)
    #             self.bus.publish_task(payload)
    #
    #         elif module == "exp" and action_type in ("RUN_EXPLOIT_SIMULATION", "RUN_EXPLOIT_PRODUCTION"):
    #             payload = {
    #                 "id": task_id,
    #                 "region": "network",
    #                 "action": "run_exploit_stage",
    #                 "target": targets,
    #                 "mode": "simulation" if action_type == "RUN_EXPLOIT_SIMULATION" else "production",
    #                 "hints": hints,
    #                 "note": notes,
    #             }
    #             logger.info("[NetworkManagerLLM] Emitting EXPLOIT task: %s", payload)
    #             self.bus.publish_task(payload)
    #
    #         elif module == "docs" and action_type == "RUN_DOC_SUMMARY":
    #             payload = {
    #                 "id": task_id,
    #                 "region": "network",
    #                 "action": "run_doc_update",
    #                 "target": targets,
    #                 "hints": hints,
    #                 "note": notes,
    #             }
    #             logger.info("[NetworkManagerLLM] Emitting DOC task: %s", payload)
    #             self.bus.publish_task(payload)
    #
    #         else:
    #             logger.warning("[NetworkManagerLLM] Unknown module/action_type: %s/%s", module, action_type)

    def _handle_cross_domain_alerts(self, task_id: str, alerts: List[Dict[str, Any]]):
        """
        Notify Pentest Orchestrator (or global manager) via DB or bus when AD/WEB/CLOUD hints appear.
        """
        if not alerts:
            return

        logger.info("[NetworkManagerLLM] Cross-domain alerts for task %s: %s", task_id, alerts)
        # simplest: store in DB; P-Orchestrator can poll / subscribe
        self.db.standard_db.insert_one({
            "type": "network_cross_domain_alert",
            "task_id": task_id,
            "alerts": alerts,
        })

    # ------------------------------------------------------------------
    # MAIN ENTRYPOINT for NetworkManager in the network domain
    # ------------------------------------------------------------------
    def run_decide_and_plan(
            self,
            task_id: str,
            scan_results: List[Dict[str, Any]],
            hints: Dict[str, Any],
            force_llm: bool = True
    ) -> Dict[str, Any]:
        """
        Main method called by the NetworkPipeline/P-Orchestrator for INPT.

        1) Use GNN (NetworkManager) to get 'delegate' vs 'deeper_scan' + probabilities.
        2) Build PTT-aware context and call LLM for next-phase/next-step plan.
        3) Update PTT state.
        4) Dispatch high-level actions to ReconManager / VAI / Exploit / Docs via EventBus.
        5) Return the final coordination meta (for logging / UI).
        """
        # 1) GNN decision
        action, probs = self.base_manager.decide(scan_results=scan_results)
        gnn_summary = self._build_gnn_summary(probs_tensor=probs, action=action)

        # simple threshold check (if you ever want pure-GNN path)
        if not force_llm and gnn_summary["margin"] >= self.gnn_confidence_threshold:
            logger.info("[NetworkManagerLLM] Using GNN-only decision for task %s", task_id)
            meta = {
                "decider": "gnn_only",
                "gnn_action": action,
                "gnn_probs": gnn_summary["probs"],
                "gnn_margin": gnn_summary["margin"],
            }
            return meta

        # 2) LLM plan
        plan_json = self._call_llm_for_plan(task_id, scan_results, gnn_summary)

        # 3) Update PTT state
        self._update_ptt_state(task_id, plan_json["ptt_state_out"], note="LLM plan update")

        # 4) Dispatch actions
        self._dispatch_actions(task_id, plan_json["recommended_actions"], hints)

        # 5) Cross-domain alerts
        self._handle_cross_domain_alerts(task_id, plan_json.get("cross_domain_alerts", []))

        # 6) Build final meta for logs/UI
        meta = {
            "decider": "gnn+llm",
            "gnn_summary": gnn_summary,
            "ptt_state": self._get_or_init_ptt_state(task_id),
            "llm_confidence": plan_json.get("confidence", 0.0),
            "recommended_actions": plan_json.get("recommended_actions", []),
        }
        return meta

# ---------------- LLM Interaction Logging ----------------
def log_llm_interaction(self, log: dict):
    """
    Saves an LLM interaction to the 'llm_logs' collection.
    Automatically adds timestamp metadata.
    """
    entry = {
        "timestamp": datetime.now(),
        **log
    }

    coll = self.db.get_collection("llm_logs")
    return coll.insert_one(entry)
