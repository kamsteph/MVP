import torch
import torch.nn.functional as F
import numpy as np
from typing import List, Dict, Any
from torch_geometric.data import Data

from Network_Pentest.network.Brain.gnn_models import VulnerabilityManagerGNN
from Network_Pentest.network.Brain.hyperparams import W_LHF, W_SERVICES, W_CVSS
from Network_Pentest.network.Managers.RL.exploitation_rl_network import ExploitationAgent
from Network_Pentest.network.utils.low_hanging_fruits import detect_low_hanging_fruits
from back_end.database import DatabaseManager
from back_end.utils.colored_logger import get_logger

logger = get_logger(__name__, component="VULN_AI_AGENT", region="AI")
THRESHOLD_LEVEL_ONE=0.3
THRESHOLD_LEVEL_TWO=0.7
class VulnerabilityAIAgent:
    def __init__(self, db: DatabaseManager, model_path: str = None, device: str = "cuda"):
        self.db = db
        self.device = torch.device(device)
        self.encoder = VulnerabilityManagerGNN(in_channels=11, hidden=64, num_classes=2).to(self.device)
        if model_path:
            self.encoder.load_state_dict(torch.load(model_path, map_location=self.device))
        self.encoder.train()  # for training
        self.policy = ExploitationAgent(db, input_dim=4, hidden=64, device=device)  # aligned input_dim

    def build_graph_features(self, scan_results: List[Dict[str, Any]], training: bool = False) -> np.ndarray:
        nodes, edges = [], set()
        for idx, r in enumerate(scan_results):
            vulns = r.get("vulnerabilities", [])
            services = r.get("services", [])
            num_vulns = len(vulns)
            max_cvss = max([v.get("cvss", 0.0) for v in vulns], default=0.0)
            has_exploit = 1 if any(v.get("exploit", False) for v in vulns) else 0
            num_services = len(services)
            risk = r.get("risk", "").lower()
            r_high, r_med, r_low = int(risk=="high"), int(risk=="medium"), int(risk=="low")

            nodes.append([
                float(num_vulns), float(max_cvss), float(has_exploit), float(num_services),
                float(r_high), float(r_med), float(r_low),
                0.0, float(num_vulns), float(num_services), 0.0
            ])

            # simple edge based on shared services
            for j in range(idx):
                s1 = [s.get("name") for s in r.get("services", []) if s.get("name")]
                s2 = [s.get("name") for s in scan_results[j].get("services", []) if s.get("name")]
                if any(x in s2 for x in s1):
                    edges.add((idx, j)); edges.add((j, idx))

        x = torch.tensor(nodes, dtype=torch.float, device=self.device)
        edge_index = torch.tensor(list(edges), dtype=torch.long, device=self.device).t().contiguous() if edges else torch.empty((2,0),dtype=torch.long,device=self.device)
        data = Data(x=x, edge_index=edge_index, batch=torch.zeros(len(nodes),dtype=torch.long,device=self.device))

        with torch.set_grad_enabled(training):
            logits = self.encoder(data.x, data.edge_index, data.batch)
            probs = F.softmax(logits, dim=1).squeeze(0).cpu().numpy()
        return probs

    def compute_vuln_score(self, vuln_record: Dict[str, Any], host_record: Dict[str, Any]) -> Dict[str, Any]:
        """
        Compute a vulnerability score based on:
          - Low-hanging fruits (easy indicators)
          - Service exposure
          - Average CVSS severity
        Returns dict with fields: {'score': float, 'level': str, 'lh_tags': list}
        """
        lh_tags, lhf_score = detect_low_hanging_fruits(vuln_record, host_record, db=self.db)
        # lhf_score returned in [0,1], lower = easier -> invert for weighting
        f_lhf = 1.0 - lhf_score

        # risky services fraction (HTTP, SMB, RDP, SSH etc.)
        risky_services = {"http", "https", "rdp", "smb", "ftp", "ssh", "telnet"}
        services = [s.get("name", "").lower() for s in host_record.get("services", [])]
        risky_count = sum(1 for s in services if s in risky_services)
        f_services = min(1.0, risky_count / max(1, len(services)))

        # average CVSS scaled 0â†’1
        vulns = host_record.get("vulnerabilities", [])
        avg_cvss = np.mean([v.get("cvss", 0.0) for v in vulns]) if vulns else 0.0
        f_cvss = avg_cvss / 10.0

        # weighted sum (lower = easier target)
        score = W_LHF * (1 - f_lhf) + W_SERVICES * f_services + W_CVSS * f_cvss
        score = max(0.0, min(1.0, score))

        level = self.assign_host_level(score)

        return {"score": score, "level": level, "lh_tags": lh_tags}

        # ------------------------------------------------------------
        # NEW: level assignment helper
        # ------------------------------------------------------------
    @staticmethod
    def assign_host_level(score: float) -> str:
        if score <= THRESHOLD_LEVEL_ONE:
            return "level_1"
        elif score <= THRESHOLD_LEVEL_TWO:
            return "level_2"
        else:
            return "level_3"


# inside VulnerabilityAIAgent

    async def analyze_surface(self, ip: str, surface: str, host_record: dict) -> dict:
        """
        Analyze one attack surface for a host.
        - host_record must be provided by the pipeline (no DB lookup here).
        - Returns a structured dict with score, level, exploit_prob, lh_tags, and optional policy_action.
        """
        try:
            if host_record is None:
                return {"ip": ip, "surface": surface, "error": "host_record_required"}

            # Prepare filtered host view for this surface
            services = host_record.get("services", []) or []
            vulns = host_record.get("vulnerabilities", []) or []
            # simple service-match: keep service entries whose name contains the surface token
            relevant_services = [s for s in services if surface.lower() in (s.get("name","").lower())]

            # Small context list for GNN (your existing format)
            context = [{
                "ip": ip,
                "services": relevant_services,
                "vulnerabilities": vulns,
                "risk": host_record.get("risk", "unknown")
            }]

            # GNN inference (no-grad by default)
            probs = self.build_graph_features(context, training=False)
            # build_graph_features returns numpy array; interpret safely:
            try:
                exploit_prob = float(probs[0]) if isinstance(probs, (list, tuple)) else float(np.asarray(probs).ravel()[-1])
            except Exception:
                exploit_prob = float(np.asarray(probs).ravel()[-1])

            # Compute vulnerability score + level using existing method
            vuln_info = self.compute_vuln_score({"surface": surface}, host_record)
            score = vuln_info.get("score", 0.0)
            level = vuln_info.get("level", "level_1")
            lh_tags = vuln_info.get("lh_tags", [])

            # Ask RL policy for recommended action (adapt to your policy API)
            # If your ExploitationAgent exposes select_action(scan_result, candidates),
            # you may instead call a helper that maps this small state to an action index.
            policy_action = None
            try:
                # example: if you have a select_action_for_state helper; if not, skip
                if hasattr(self.policy, "select_action_for_state"):
                    state_vec = [score, exploit_prob, len(relevant_services), len(vulns)]
                    policy_action = self.policy.select_action_for_state(state_vec)
            except Exception:
                policy_action = None

            result = {
                "ip": ip,
                "surface": surface,
                "exploit_prob": exploit_prob,
                "score": score,
                "level": level,
                "lh_tags": lh_tags,
                "policy_action": policy_action,
                "host_record_ref": {"ip": ip}  # keep as pointer for audits
            }
            logger.info(f"[VAI] analyze_surface {ip}/{surface} -> score={score:.3f} prob={exploit_prob:.3f}")
            return result

        except Exception as e:
            logger.exception("[VAI] analyze_surface failed: %s", e)
            return {"ip": ip, "surface": surface, "error": str(e)}
