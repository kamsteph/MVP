from datetime import datetime
from back_end.database import DatabaseManager
from Network_Pentest.network.Brain.hyperparams import HINT_DECAY_DAILY_FACTOR, HINT_BAYES_ALPHA, HINT_BAYES_BETA
import math

db = DatabaseManager()

def _apply_decay(old_count, days_elapsed, daily_factor):
    """Apply exponential decay to a count given number of days elapsed."""
    return old_count * (daily_factor ** days_elapsed)

def record_outcome(attack_surface: str, tool_name: str, success: bool):
    """
    Bayesian + decay update for tool hint.
    Stores record in collection 'tool_priority_hints' with schema:
      {
         "attack_surface": str,
         "tool": str,
         "alpha": float,
         "beta": float,
         "last_updated": datetime,
         "total_count": float,   # effective (decayed) count
         "score": float,         # posterior mean alpha/(alpha+beta)
         "confidence": float     # derived from counts
      }
    """
    coll = db.db.get_collection("tools_priority")
    now = datetime.now()

    existing = coll.find_one({"attack_surface": attack_surface, "tool": tool_name})
    if existing:
        # compute days elapsed for decay
        last = existing.get("last_updated", now)
        if isinstance(last, str):
            # if stored as iso string
            last = datetime.fromisoformat(last)
        days = (now - last).total_seconds() / 86400.0
        days = max(0.0, days)
        # decay previous effective counts
        eff_alpha = _apply_decay(existing.get("alpha", HINT_BAYES_ALPHA), days, HINT_DECAY_DAILY_FACTOR)
        eff_beta  = _apply_decay(existing.get("beta", HINT_BAYES_BETA), days, HINT_DECAY_DAILY_FACTOR)
    else:
        eff_alpha = HINT_BAYES_ALPHA
        eff_beta  = HINT_BAYES_BETA

    # incorporate new observation: success -> +1 alpha, else +1 beta
    if success:
        eff_alpha += 1.0
    else:
        eff_beta += 1.0

    # compute posterior mean and effective count
    score = eff_alpha / (eff_alpha + eff_beta)
    eff_count = eff_alpha + eff_beta
    # confidence heuristic: sqrt of effective count normalized (you can tune)
    confidence = min(1.0, math.sqrt(eff_count) / 10.0)  # 100 counts -> conf ~1.0

    doc = {
        "attack_surface": attack_surface,
        "tool": tool_name,
        "alpha": float(eff_alpha),
        "beta": float(eff_beta),
        "last_updated": now.isoformat(),
        "total_count": float(eff_count),
        "score": float(score),
        "confidence": float(confidence)
    }
    coll.update_one({"attack_surface": attack_surface, "tool": tool_name},
                    {"$set": doc}, upsert=True)
