# new_module/ai_agents/exploitation_ai_agent_v2.py
"""
ExploitationAIAgentV2
---------------------
Next-gen hybrid agent combining:
 - ExploitManagerGNN for exploit graph context
 - DQN-style ExploitationAgent for decision learning
 - Dynamic exploit APIs (Metasploit, custom, CLI-based, etc.)
"""

import torch
import numpy as np
from typing import List, Dict, Any

from Network_Pentest.network.Managers.exploitation_rl_network import ExploitationAgent, default_state_encoder
from Network_Pentest.network.tool.base_class import get_tool_by_name, list_registered_tools
from back_end.database import DatabaseManager
from back_end.utils.colored_logger import get_logger

from Network_Pentest.network.Brain.gnn_models import ExploitManagerGNN

logger = get_logger(__name__, component="EXPLOIT_AI_AGENT_V2", region="AI")


class ExploitationAIAgentV2:
    def __init__(self, db: DatabaseManager, model_path: str = None, device: str = "cpu"):
        self.db = db
        self.device = torch.device(device)

        # 1 Context encoder (GNN)
        self.encoder = ExploitManagerGNN(in_channels=6, hidden=48, heads=6).to(self.device)
        if model_path:
            self.encoder.load_state_dict(torch.load(model_path, map_location=self.device))
        self.encoder.eval()

        # Reinforcement learner (Q-learning policy)
        self.policy = ExploitationAgent(db, input_dim=5, hidden=64, lr=1e-3, device=device)

        #  Dynamic exploit registry
        self.available_tools = list_registered_tools()
        logger.info(f"Available exploit tools: {list(self.available_tools.keys())}")

    # -----------------------------------------------------
    # Graph encoding: generate latent exploit features
    # -----------------------------------------------------
    def build_graph_features(self, candidates: List[Dict[str, Any]]) -> np.ndarray:
        nodes, edges = [], []
        for i, c in enumerate(candidates):
            sev = float(c.get("severity", 0.0))
            port = float(c.get("port", 0.0))
            is_http = 1.0 if c.get("service", "").lower() == "http" else 0.0
            prev = 1.0 if c.get("previous_success", False) else 0.0
            age = float(c.get("exploit_age", 0.0))
            mem = 0.0
            nodes.append([sev, port, is_http, prev, age, mem])
            for j in range(i):
                if abs(port - float(candidates[j].get("port", 0))) <= 0:
                    edges.append((i, j)); edges.append((j, i))
        x = torch.tensor(nodes, dtype=torch.float, device=self.device)
        edge_index = torch.tensor(edges, dtype=torch.long, device=self.device).t().contiguous() if edges else torch.empty((2,0), dtype=torch.long, device=self.device)
        with torch.no_grad():
            out = self.encoder(x, edge_index)
            logits = out["success_logits"].detach().cpu().numpy().flatten()
        return logits

    # -----------------------------------------------------
    # Decision & execution phase
    # -----------------------------------------------------
    async def choose_and_execute(self, scan_result: Dict[str, Any], candidates: List[Dict[str, Any]], epsilon: float = 0.1):
        if not candidates:
            logger.warning("No candidate exploits provided.")
            return None

        # 1 Encode current state
        state_vec = default_state_encoder(scan_result, candidates)
        gat_features = self.build_graph_features(candidates)
        combined_state = np.concatenate([state_vec, [float(gat_features.mean())]])

        # 2 Select exploit via DQN policy
        action_idx = self.policy.select_action(scan_result, candidates, epsilon=epsilon)
        selected = candidates[action_idx]
        target_ip = scan_result.get("ip", "127.0.0.1")
        port = selected.get("port")
        exploit_tool = selected.get("tool", "metasploit").lower()

        # 3 Get exploiter from registry
        tool = get_tool_by_name(exploit_tool)
        if not tool:
            logger.warning(f"Exploit tool '{exploit_tool}' not registered. Skipping.")
            return {"error": f"Tool {exploit_tool} not available."}

        mode = scan_result.get("mode", "live")  # "train" or "live"
        if mode == "train":
            logger.info("[TRAINING] Executing exploit against GAN honeypot")
        else:
            logger.info("[LIVE] Executing exploit against real target")

        # 4 Execute asynchronously
        logger.info(f"[AI] Executing {selected.get('id')} using {exploit_tool} on {target_ip}:{port}")
        try:
            result = await tool.run_safe(target_ip, exploit_vector=selected)
        except Exception as e:
            logger.error(f"Execution failed: {e}")
            result = {"status": "error", "error": str(e)}

        # 5 Reward + experience storage
        success = result.get("status", "").startswith("executed") or "success" in str(result).lower()
        reward = 1.0 if success else -0.2

        self.policy.store_experience(
            state_vec=combined_state.tolist(),
            action_idx=action_idx,
            reward=reward,
            next_state_vec=combined_state.tolist(),
            done=False
        )
        loss = self.policy.learn_from_experience(batch_size=16)

        logger.info(f"[AI] Completed run via {exploit_tool} â†’ reward={reward:.2f}, loss={loss:.4f}")

        return {
            "selected_exploit": selected,
            "target": target_ip,
            "tool": exploit_tool,
            "result": result,
            "reward": reward,
            "loss": loss
        }
