#!/usr/bin/env python3
"""
ETL: extract exploit assets (PoC URLs, references, etc.) from your ADB (augmented_database)
and insert them into `exploit_assets` collection.

Usage:
  # preview (no DB writes):
  python etl_extract_exploit_assets.py --dry-run

  # commit (write to DB):
  python etl_extract_exploit_assets.py --commit --limit 1000

Options:
  --dry-run (default): do not write, just report
  --commit: write to DB (upsert by value)
  --limit N: process only N CVE docs (for testing)
  --source_field FIELD: look for PoCs in an extra field name
"""

import argparse
import logging
import re
from urllib.parse import urlparse
from back_end.database import DatabaseManager
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("etl_extract_exploit_assets")

def extract_urls_from_doc(doc):
    """
    Defensive extraction of URLs from fields that may contain PoC links.
    Returns a deduplicated list of URLs (strings).
    """
    urls = set()

    # common explicit fields
    for f in ("exploit_urls", "pocs", "poc_urls", "references"):
        if doc.get(f):
            if isinstance(doc[f], list):
                for v in doc[f]:
                    try:
                        if isinstance(v, dict) and v.get("url"):
                            urls.add(v.get("url"))
                        elif isinstance(v, str):
                            urls.add(v)
                    except Exception:
                        continue
            elif isinstance(doc[f], str):
                urls.add(doc[f])

    # nvd_raw nested references
    if doc.get("nvd_raw"):
        try:
            for r in doc["nvd_raw"]:
                refs = r.get("references") or []
                for item in refs:
                    if isinstance(item, dict) and item.get("url"):
                        urls.add(item.get("url"))
        except Exception:
            pass

    # Search free text (summary, description) for exploit-db or github links as a last resort
    text_fields = []
    if doc.get("summary"):
        text_fields.append(doc.get("summary"))
    if doc.get("description"):
        text_fields.append(doc.get("description"))
    for t in text_fields:
        if not t:
            continue
        # simple regex for http(s) links
        found = re.findall(r"https?://[^\s)'\"]+", t)
        for u in found:
            urls.add(u)

    # sanitize and normalize urls
    clean = set()
    for u in urls:
        try:
            parsed = urlparse(u.strip())
            if parsed.scheme in ("http", "https") and parsed.netloc:
                clean.add(u.strip())
        except Exception:
            continue

    return sorted(clean)

def build_asset_doc_from_url(cve_doc, url):
    """
    Build a canonical exploit_asset document for a URL.
    Example fields:
      - type: "poc_url"
      - value: URL
      - cves: [CVE-...]
      - service/vendor/product if present
      - confidence: 0.6 (heuristic)
      - source: where we found it (field name)
    """
    cve = (cve_doc.get("cve") or cve_doc.get("id") or "").upper()
    vendor = None
    product = None
    service = None
    cvss = float(cve_doc.get("cvss") or 0.0)

    # try to extract service/product heuristics from summary or nvd_raw
    summary = cve_doc.get("summary", "") or ""
    lower = summary.lower()
    if "ssh" in lower or "telnet" in lower:
        service = "ssh" if "ssh" in lower else "telnet"
    if "mysql" in lower:
        service = "mysql"

    asset = {
        "asset_id": None,  # optional, left None for Mongo to assign _id
        "cves": [cve] if cve else [],
        "type": "poc_url",
        "value": url,
        "service": service,
        "port": None,
        "vendor": vendor,
        "product": product,
        "cvss": cvss,
        "evidence": ["adb_extraction"],
        "safe_for_training": False,
        "exec_template": None,
        "confidence": 0.5,
        "last_verified": None,
        "notes": f"Extracted from adb doc _id={str(cve_doc.get('_id'))}",
        "created_at": datetime.now()
    }
    return asset

def etl(dry_run=True, limit=None, commit=False):
    db = DatabaseManager()
    col = db.adb  # augmented_database
    total = 0
    processed = 0
    cursor = col.find({})
    if limit:
        cursor = cursor.limit(limit)

    for doc in cursor:
        total += 1
        urls = extract_urls_from_doc(doc)
        if not urls:
            continue
        for u in urls:
            asset = build_asset_doc_from_url(doc, u)
            processed += 1
            logger.info(f"[ETL] Found asset for CVE {asset['cves']} -> {u}")
            if commit:
                # upsert by value (URL) to avoid duplicates
                db.upsert_exploit_asset({"value": asset["value"]}, asset)
    logger.info(f"Done. Total CVE docs scanned: {total}, assets extracted: {processed}")
    if dry_run:
        logger.info("Dry-run: no DB writes were performed.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--commit", action="store_true", help="Write assets to DB (upsert).")
    parser.add_argument("--limit", type=int, default=None, help="Limit CVE docs to process.")
    parser.add_argument("--dry-run", action="store_true", default=True, help="Do not write to DB (default). Use --commit to write.")
    args = parser.parse_args()
    etl(dry_run=not args.commit, limit=args.limit, commit=args.commit)
