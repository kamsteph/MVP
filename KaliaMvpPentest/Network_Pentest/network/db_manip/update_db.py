# update_db.py
import os
import re
import json
import time
import requests
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

from Network_Pentest.network.db_manip.db_flagging import is_network_related
from back_end.database import DatabaseManager

# ================================
# CONFIGURATION
# ================================
NVD_API = "https://services.nvd.nist.gov/rest/json/cves/2.0"
API_KEY = os.getenv("NVD_API_KEY", None)  # set this in your env
HEADERS = {"apiKey": API_KEY} if API_KEY else {}

BATCH_SIZE = 500       # CVEs per batch before checkpoint
THREADS = 2          # parallel requests (respecting rate limits)
SLEEP = 0.5 if API_KEY else 1.2  # API key allows up to 50 req/s
CHECKPOINT_FILE = "./nvd_checkpoint.json"


# ================================
# UTILITIES
# ================================
def load_checkpoint():
    """Load last processed index from file."""
    if os.path.exists(CHECKPOINT_FILE):
        with open(CHECKPOINT_FILE, "r") as f:
            return json.load(f)
    return {"last_index": 0, "processed": 0, "updated": 0, "network": 0}


def save_checkpoint(data):
    """Save checkpoint progress."""
    with open(CHECKPOINT_FILE, "w") as f:
        json.dump(data, f, indent=2)


def get_cve_from_nvd(cve_id: str):
    """Fetch CVE details directly from NVD API."""
    try:
        url = f"{NVD_API}?cveId={cve_id}"
        r = requests.get(url, headers=HEADERS, timeout=30)
        if r.status_code == 200:
            js = r.json()
            if "vulnerabilities" in js and js["vulnerabilities"]:
                return js["vulnerabilities"][0]["cve"]
        else:
            print(f"‚ö†Ô∏è Failed {cve_id}: {r.status_code}")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è Error fetching {cve_id}: {e}")
        return None


def enrich_record(local, nvd_cve):
    """Merge NVD data without overwriting existing info."""
    updated = False
    metrics = (
            nvd_cve.get("metrics", {}).get("cvssMetricV31")
            or nvd_cve.get("metrics", {}).get("cvssMetricV30")
            or []
    )
    cvss_data = metrics[0]["cvssData"] if metrics else {}

    descs = nvd_cve.get("descriptions", [])
    summary = descs[0]["value"] if descs else None
    refs = [r["url"] for r in nvd_cve.get("references", [])]
    weaknesses = [
        w["description"][0]["value"]
        for w in nvd_cve.get("weaknesses", [])
        if w.get("description")
    ]

    # Fill only missing fields
    if not local.get("summary") and summary:
        local["summary"] = summary; updated = True
    if not local.get("references") and refs:
        local["references"] = refs; updated = True
    if not local.get("weaknesses") and weaknesses:
        local["weaknesses"] = weaknesses; updated = True
    if not local.get("cvss") and cvss_data.get("baseScore"):
        local["cvss"] = cvss_data["baseScore"]; updated = True
    if not local.get("severity") and cvss_data.get("baseSeverity"):
        local["severity"] = cvss_data["baseSeverity"]; updated = True
    if not local.get("publishedDate") and nvd_cve.get("published"):
        local["publishedDate"] = nvd_cve["published"]; updated = True

    # Save NVD raw
    local.setdefault("nvd_raw", [])
    local["nvd_raw"].append(nvd_cve)

    return local, updated


def process_cve(doc, db):
    """Worker to fetch and enrich a single CVE."""
    cve_id = doc.get("cve")
    if not cve_id:
        return (0, 0)

    nvd_cve = get_cve_from_nvd(cve_id)
    if not nvd_cve:
        return (0, 0)

    enriched, changed = enrich_record(doc, nvd_cve)
    if is_network_related(enriched.get("summary", "")):
        enriched["is_network_related"] = True
        net_flag = 1
    else:
        net_flag = 0

    if changed or net_flag:
        db.adb_collection.update_one({"_id": doc["_id"]}, {"$set": enriched})
        return (1, net_flag)
    return (0, net_flag)


# ================================
# MAIN UPDATE FUNCTION
# ================================
def run_update():
    db = DatabaseManager()
    total_docs = db.adb_collection.count_documents({})
    if total_docs == 0:
        print("üö´ No CVEs found in DB ‚Äî please import first.")
        return

    ckpt = load_checkpoint()
    last_index = ckpt["last_index"]
    print(f"üîÅ Resuming from index {last_index}...")

    cursor = db.adb_collection.find({}, {"_id": 1, "cve": 1, "summary": 1}).skip(last_index)
    total_updated = ckpt["updated"]
    total_network = ckpt["network"]
    processed = ckpt["processed"]

    print(f"üöÄ Starting enrichment ({total_docs - last_index} CVEs remaining)...")

    with ThreadPoolExecutor(max_workers=THREADS) as executor:
        futures = []
        for i, doc in enumerate(cursor, start=last_index + 1):
            futures.append(executor.submit(process_cve, doc, db))
            time.sleep(SLEEP)  # respect rate limit

            # Checkpoint + status
            if i % BATCH_SIZE == 0:
                for f in as_completed(futures):
                    upd, net = f.result()
                    total_updated += upd
                    total_network += net
                    processed += 1
                futures.clear()
                ckpt = {
                    "last_index": i,
                    "processed": processed,
                    "updated": total_updated,
                    "network": total_network,
                }
                save_checkpoint(ckpt)
                print(f"üåÄ Checkpoint @ {i}/{total_docs} ‚Äî {total_updated} updated, {total_network} network")
        # finalize remaining
        for f in as_completed(futures):
            upd, net = f.result()
            total_updated += upd
            total_network += net

    # Final checkpoint
    save_checkpoint({
        "last_index": total_docs,
        "processed": total_docs,
        "updated": total_updated,
        "network": total_network
    })

    print("\nüéØ Done enriching CVEs.")
    print(f"üìà Total updated: {total_updated}")
    print(f"üåê Network-related CVEs flagged: {total_network}")


if __name__ == "__main__":
    run_update()
