# new_module/utils/metrics.py
"""
Metrics utilities for evaluating GNNs during training or inference.
All results are optionally stored in MongoDB (standard_db collection).
"""

import torch
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from back_end.database import DatabaseManager
from datetime import datetime

class MetricsRecorder:
    def __init__(self, db_logging: bool = True):
        self.db = DatabaseManager() if db_logging else None
        self.db_logging = db_logging

    def classification_metrics(self, y_true, y_pred, probs=None, phase="validation", model_name="Unknown"):
        """Compute accuracy, precision, recall, f1, (optionally auc if binary)"""
        y_true = torch.tensor(y_true).cpu().numpy()
        y_pred = torch.tensor(y_pred).cpu().numpy()

        metrics = {
            "accuracy": float(accuracy_score(y_true, y_pred)),
            "precision": float(precision_score(y_true, y_pred, average="weighted", zero_division=0)),
            "recall": float(recall_score(y_true, y_pred, average="weighted", zero_division=0)),
            "f1": float(f1_score(y_true, y_pred, average="weighted", zero_division=0)),
        }

        if probs is not None and len(set(y_true)) == 2:
            try:
                metrics["roc_auc"] = float(roc_auc_score(y_true, probs))
            except Exception:
                metrics["roc_auc"] = None

        # Store in DB if enabled
        if self.db_logging and self.db:
            record = {
                "timestamp": datetime.utcnow(),
                "phase": phase,
                "model": model_name,
                "metrics": metrics
            }
            self.db.standard_db.insert_one(record)

        return metrics

    def print_metrics(self, metrics: dict):
        print("Metrics:")
        for k, v in metrics.items():
            print(f"   {k:10s}: {v:.4f}")
