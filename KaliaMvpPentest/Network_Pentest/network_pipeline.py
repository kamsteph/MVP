"""
NetworkPipeline
---------------
Connects ReconManager → NetworkManager → VulnerabilityAIAgent
using the EventBus as the orchestration layer.
"""

import asyncio
from typing import Dict, Any

from Network_Pentest.network.Managers.network_recon_manager import ReconManager
from back_end.event_bus import EventBus
from back_end.database import DatabaseManager

from Network_Pentest.network.Managers.network_manager import NetworkManager
from Network_Pentest.network.Managers.network_vuln_manager import VulnerabilityAIAgent
from back_end.utils.colored_logger import get_logger

logger = get_logger(__name__, component="NETWORK_PIPELINE", region="NETWORK")


class NetworkPipeline:
    def __init__(self, model_path: str = None, device: str = "cpu"):
        # Core components
        self.bus = EventBus()
        self.db = DatabaseManager()
        self.vuln_agent = VulnerabilityAIAgent(self.db, device=device)
        self.network_manager = NetworkManager(model_path=model_path, device=device)
        self.recon_manager = ReconManager(bus=self.bus, db=self.db, vulnscan_mgr=self.vuln_agent)

        # Subscriptions
        self.bus.subscribe("network_recon_done", self.on_recon_done)
        self.bus.subscribe("network_vuln_scan", self.on_vuln_scan)

        logger.info("NetworkPipeline initialized and all event routes connected.")

    # ------------------------------------------------------------
    # Stage 1: Recon finished → trigger NetworkManager
    # ------------------------------------------------------------
    def on_recon_done(self, message: Dict[str, Any]):
        """Handle results from ReconManager, trigger mapping and next-step decision."""
        task_id = message.get("id")
        results = message.get("results", [])
        hints = message.get("hints", {})
        logger.info(f"[Pipeline] Received recon results for task {task_id}, {len(results)} hosts.")

        try:
            # Let the GNN decide what to do next
            action, probs = self.network_manager.decide(results)
            logger.info(f"[Pipeline] NetworkManager decided: {action} (probs={probs.tolist()})")

            if action == "deeper_scan":
                # send task for vulnerability scanning
                self.bus.publish_task({
                    "id": task_id,
                    "action": "network_vuln_scan",
                    "targets": [r["ip"] for r in results if r.get("alive")],
                    "recon_results": results,
                    "hints": hints
                })
            else:
                logger.info(f"[Pipeline] Task {task_id}: decision=delegate (no deeper scan)")
        except Exception as e:
            logger.error(f"[Pipeline] Error during network mapping/decision: {e}")

    # ------------------------------------------------------------
    # Stage 2: Vulnerability scanning
    # ------------------------------------------------------------
    async def on_vuln_scan(self, message: Dict[str, Any]):
        task_id = message.get("id")
        targets = message.get("targets", [])
        hints = message.get("hints", {})
        recon_results = message.get("recon_results", [])

        logger.info(f"[Pipeline] Starting AI vulnerability scan for {len(targets)} targets (task {task_id}).")

        results = []

        async def analyze_host(ip, host_record):
            host_results = []
            surfaces = hints.get("attack_surfaces", ["web", "ssh", "ftp"])
            # run all surfaces concurrently for this host
            tasks = [self.vuln_agent.analyze_surface(ip, surf, host_record=host_record) for surf in surfaces]
            completed = await asyncio.gather(*tasks, return_exceptions=True)
            for c in completed:
                if isinstance(c, Exception):
                    host_results.append({"ip": ip, "error": str(c)})
                else:
                    host_results.append(c)
            return host_results

        # Build mapping ip -> host_record for quick lookup
        recon_map = {r.get("ip"): r for r in recon_results if r.get("ip")}

        # create tasks for all hosts that have recon records
        host_tasks = []
        for ip in targets:
            host_record = recon_map.get(ip)
            if not host_record:
                logger.warning(f"[Pipeline] No recon record for {ip}; skipping.")
                results.append({"ip": ip, "error": "no_recon_record"})
                continue
            host_tasks.append(analyze_host(ip, host_record))

        # run all host tasks concurrently (bounded if needed)
        if host_tasks:
            all_hosts_out = await asyncio.gather(*host_tasks, return_exceptions=True)
            for h in all_hosts_out:
                if isinstance(h, Exception):
                    results.append({"error": str(h)})
                else:
                    results.extend(h)

        # Persist final results
        self.db.save_scan_result({
            "task_id": task_id,
            "type": "network_vuln_scan",
            "results": results
        })
        logger.info(f"[Pipeline] Vulnerability scanning complete for task {task_id}.")

    # ------------------------------------------------------------
    # Entry point
    # ------------------------------------------------------------
    async def run(self, target_spec: Any, task_id: str = "task_auto", hints: Dict[str, Any] = None):
        """
        Kick off the entire process by publishing a recon scan event.
        """
        hints = hints or {}
        logger.info(f"[Pipeline] Launching full network pipeline on target(s): {target_spec}")
        self.bus.publish_task({
            "id": task_id,
            "action": "network_recon_scan",
            "target": target_spec,
            "hints": hints
        })
        # Wait for all async subtasks to complete
        await asyncio.sleep(5)
