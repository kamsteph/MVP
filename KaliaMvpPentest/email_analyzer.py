#!/usr/bin/env python3
"""
email_analyzer.py

Usage:
    python email_analyzer.py /path/to/email.eml            # analyze and print JSON
    python email_analyzer.py /path/to/email.eml --out out.json  # save full JSON

Produces summary to stdout and JSON details (if --out).
"""

import sys
import os
import re
import json
import argparse
import hashlib
from email import policy
from email.parser import BytesParser
from email.message import EmailMessage
from typing import List, Dict, Any, Tuple, Optional
from urllib.parse import urlparse
import base64

# optional libs
try:
    import dkim
except Exception:
    dkim = None

try:
    import spf
except Exception:
    spf = None

try:
    import tldextract
except Exception:
    tldextract = None

IP_REGEX = re.compile(r'(?:(?:\d{1,3}\.){3}\d{1,3})|(?:\[[0-9a-fA-F:.]+\])')

def load_email(path: str) -> EmailMessage:
    with open(path, "rb") as f:
        msg = BytesParser(policy=policy.default).parse(f)
    return msg

def header_get(msg: EmailMessage, name: str):
    return msg.get(name)

def extract_urls_from_text(text: str) -> List[str]:
    # simple URL regex - good enough for common links
    url_re = re.compile(r'https?://[^\s"\'<>]+', re.IGNORECASE)
    return url_re.findall(text or "")

def normalize_url(url: str) -> str:
    try:
        return url.strip()
    except Exception:
        return url


# ----- BEGIN: user-focused extraction helpers -----
import html
from email.utils import parseaddr
from bs4 import BeautifulSoup

# Optional: pillow for EXIF
try:
    from PIL import Image
    from PIL.ExifTags import TAGS, GPSTAGS
except Exception:
    Image = None

def parse_from_header(from_header: str) -> Dict[str, str]:
    """
    Return {'display_name': ..., 'address': ..., 'local': ..., 'domain': ...}
    """
    name, addr = parseaddr(from_header or "")
    local, domain = "", ""
    if "@" in addr:
        parts = addr.split("@", 1)
        local, domain = parts[0], parts[1].lower()
    return {"display_name": name or None, "address": addr or None, "local": local, "domain": domain}

def extract_message_id_host(message_id: str) -> Optional[str]:
    """
    Parse domain/host inside Message-ID if present.
    Example: <abc123@mail.example.com> -> mail.example.com
    """
    if not message_id:
        return None
    m = re.search(r'@([^>]+)>?$', message_id)
    if m:
        return m.group(1).lower().strip()
    return None

def pick_likely_origin_ip(received_unique_ips: List[str]) -> Optional[str]:
    """
    Heuristic: the earliest hop (last in Received list) is often the sending client.
    We pick the last public IPv4 in the list; ignore private RFC1918.
    `received_unique_ips` should be ordered as extracted (newest-to-oldest or oldest-to-newest depending on parsing).
    In our analyzer parsed_received came in raw header order; `received_unique_ips` preserves order seen.
    We'll pick the last IP that is public.
    """
    def is_private(ip: str) -> bool:
        # reuse is_private_ip from file if present
        try:
            return is_private_ip(ip)
        except Exception:
            return False

    for ip in reversed(received_unique_ips or []):
        if not ip:
            continue
        ip_clean = ip.strip("[]")
        if not is_private(ip_clean):
            # naive IPv4 only check; accept IPv6 too
            return ip_clean
    return None

def detect_tracking_pixels_from_html(html_text: str) -> List[Dict[str, Any]]:
    """
    Return list of detected tiny images or remote images likely to be trackers.
    Looks for <img> tags with width/height 1, or src with 'pixel' or 'track' or query params typical of trackers.
    """
    results = []
    if not html_text:
        return results
    # Prefer BeautifulSoup if available (more robust), otherwise fall back to regex
    try:
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_text, "html.parser")
        imgs = soup.find_all("img")
        for img in imgs:
            src = img.get("src") or ""
            width = img.get("width")
            height = img.get("height")
            style = img.get("style") or ""
            # attempt numeric sizes
            tiny = False
            try:
                w = int(width) if width else None
                h = int(height) if height else None
                if (w == 1 and h == 1) or ("1px" in style):
                    tiny = True
            except Exception:
                pass
            # heuristics on src
            src_lower = src.lower()
            if tiny or "pixel" in src_lower or "track" in src_lower or "open" in src_lower or "img.gif" in src_lower or ("?" in src and "utm" in src_lower):
                results.append({"src": src, "tiny_flag": tiny, "style": style})
    except Exception:
        # fallback: regex for img src and obvious trackers
        for m in re.finditer(r'<img[^>]+src=["\']([^"\']+)["\']', html_text, re.I):
            src = m.group(1)
            if re.search(r'(pixel|track|open|img\.gif|\butm_|1x1)', src, re.I):
                results.append({"src": src, "tiny_flag": False})
    return results

def extract_image_exif_from_attachment(path: str) -> Dict[str, Any]:
    """
    If Pillow is installed and attachment is an image, return common EXIF fields.
    """
    if Image is None:
        return {"error": "Pillow not installed"}
    try:
        im = Image.open(path)
        info = {}
        exif = im._getexif()
        if not exif:
            return {}
        for tag, val in exif.items():
            name = TAGS.get(tag, tag)
            info[name] = val
        # Basic GPS decoding (if present)
        gps = {}
        gpsinfo = exif.get(34853) or exif.get('GPSInfo')
        if gpsinfo:
            for key in gpsinfo:
                name = GPSTAGS.get(key, key)
                gps[name] = gpsinfo[key]
            info['GPS'] = gps
        return info
    except Exception as e:
        return {"error": str(e)}
# ----- END: user-focused extraction helpers -----

def compute_hashes(data: bytes) -> Dict[str, str]:
    return {
        "md5": hashlib.md5(data).hexdigest(),
        "sha1": hashlib.sha1(data).hexdigest(),
        "sha256": hashlib.sha256(data).hexdigest()
    }

def parse_received(received_value: str) -> Dict[str, Any]:
    """
    Very permissive parse of a Received header line to extract:
    - raw text
    - any IPv4/IPv6 addresses found (in order)
    - any hostnames that look like words followed by dots
    """
    ips = IP_REGEX.findall(received_value)
    # extract hostnames (very permissive)
    host_re = re.compile(r'([a-z0-9.-]+\.[a-z]{2,})', re.I)
    hosts = host_re.findall(received_value)
    return {"raw": received_value, "ips": ips, "hosts": hosts}

def is_private_ip(addr: str) -> bool:
    # naive private IP check for IPv4 only (string)
    if not addr:
        return False
    if addr.startswith('[') and addr.endswith(']'):
        addr = addr.strip('[]')
    parts = addr.split('.')
    if len(parts) == 4:
        try:
            o1, o2, o3, o4 = [int(p) for p in parts]
        except Exception:
            return False
        if o1 == 10:
            return True
        if o1 == 172 and 16 <= o2 <= 31:
            return True
        if o1 == 192 and o2 == 168:
            return True
    return False

def domain_of_email(addr: str) -> str:
    if not addr:
        return ""
    m = re.search(r'@([^> )]+)', addr)
    return m.group(1).lower() if m else ""

def extract_attachments(msg: EmailMessage, out_dir: str) -> List[Dict[str, Any]]:
    """
    Save attachments to out_dir and return list of metadata: filename, content-type, size, hashes
    """
    os.makedirs(out_dir, exist_ok=True)
    attachments = []
    for part in msg.iter_attachments():
        payload = part.get_payload(decode=True)
        filename = part.get_filename() or "part-{}.bin".format(len(attachments)+1)
        filepath = os.path.join(out_dir, filename)
        try:
            with open(filepath, "wb") as f:
                f.write(payload)
        except Exception:
            # fallback unique name
            filepath = os.path.join(out_dir, f"saved-{len(attachments)+1}.bin")
            with open(filepath, "wb") as f:
                f.write(payload)

        meta = {
            "filename": filename,
            "saved_to": filepath,
            "content_type": part.get_content_type(),
            "size": len(payload) if payload else 0,
            "hashes": compute_hashes(payload if payload else b"")
        }
        attachments.append(meta)
    return attachments

def gather_mail_analysis(msg: EmailMessage, save_attachments_dir: str = "./eml_attachments", do_verify_dkim_spf: bool = False) -> Dict[str, Any]:
    results: Dict[str, Any] = {}
    # top headers
    results["subject"] = header_get(msg, "Subject")
    results["from"] = header_get(msg, "From")
    results["to"] = header_get(msg, "To")
    results["date"] = header_get(msg, "Date")
    results["message_id"] = header_get(msg, "Message-ID")
    results["return_path"] = header_get(msg, "Return-Path")
    results["reply_to"] = header_get(msg, "Reply-To")
    results["list_unsubscribe"] = header_get(msg, "List-Unsubscribe")
    results["dkim_signature"] = header_get(msg, "DKIM-Signature")
    results["authentication_results"] = header_get(msg, "Authentication-Results")
    results["received_spf"] = header_get(msg, "Received-SPF") or header_get(msg, "Received-SPF")

    # Received headers (ordered as in message; RFC typically newest first)
    recvd = msg.get_all("Received") or []
    parsed_received = [parse_received(r) for r in recvd]
    results["received"] = parsed_received

    # received IPs and basic heuristics
    ips_ordered = []
    for p in parsed_received:
        for ip in p["ips"]:
            # normalize IPv6 bracketed forms
            ip_norm = ip.strip("[]")
            ips_ordered.append(ip_norm)
    results["received_ips_ordered"] = ips_ordered
    results["received_unique_ips"] = list(dict.fromkeys(ips_ordered))

    # Heuristics: suspicious indicators
    indicators = []
    # mismatch between envelope (Return-Path) domain and From: domain
    from_dom = domain_of_email(results["from"] or "")
    envelope_dom = domain_of_email(results["return_path"] or "")
    if from_dom and envelope_dom and from_dom != envelope_dom:
        indicators.append({
            "type": "envelope_from_mismatch",
            "detail": f"From domain '{from_dom}' != Return-Path domain '{envelope_dom}'"
        })
    # private IPs in Received
    private_ips = [ip for ip in results["received_unique_ips"] if is_private_ip(ip)]
    if private_ips:
        indicators.append({"type": "private_ips_in_received", "ips": private_ips})

    # parse body & text/plain and text/html
    body_text = ""
    body_html = ""
    urls = []
    for part in msg.walk():
        ctype = part.get_content_type()
        if part.is_multipart():
            continue
        payload = part.get_payload(decode=True)
        if not payload:
            continue
        try:
            text = payload.decode(part.get_content_charset(failobj="utf-8"), errors="replace")
        except Exception:
            try:
                text = payload.decode("utf-8", errors="replace")
            except Exception:
                text = ""
        if ctype == "text/plain":
            body_text += "\n" + text
            urls += extract_urls_from_text(text)
        elif ctype == "text/html":
            body_html += "\n" + text
            urls += extract_urls_from_text(text)
        else:
            # other content types (attachments handled separately)
            pass

    results["body_text_snippet"] = (body_text or body_html)[:1000]
    # normalize and unique URLs
    normalized_urls = [normalize_url(u) for u in urls]
    results["urls"] = list(dict.fromkeys(normalized_urls))

    # list of domains from URLs (extract tldextract if available otherwise fallback)
    url_domains = []
    for u in results["urls"]:
        try:
            parsed = urlparse(u)
            host = parsed.hostname
            if host:
                if tldextract:
                    te = tldextract.extract(host)
                    domain = ".".join([p for p in (te.domain, te.suffix) if p])
                else:
                    domain = host
                url_domains.append(domain)
        except Exception:
            continue
    results["url_domains"] = list(dict.fromkeys(url_domains))

    # attachments: save and hash
    attachments = extract_attachments(msg, save_attachments_dir)
    results["attachments"] = attachments

    # flag suspicious attachments (exe, js, office macros indicators)
    suspicious_ext = []
    for att in attachments:
        nm = att["filename"].lower()
        if nm.endswith((".exe", ".scr", ".pif", ".bat", ".cmd", ".js", ".jse")):
            suspicious_ext.append(att["filename"])
        if nm.endswith((".doc", ".docm", ".xls", ".xlsm", ".ppt", ".pptm")):
            suspicious_ext.append(att["filename"])
    if suspicious_ext:
        indicators.append({"type": "suspicious_attachments", "files": suspicious_ext})

    # existing: results["indicators"] = indicators
    results["indicators"] = indicators

    # ---------------- user-focused signals ----------------
    # parse From header for display name and local part
    results["sender_profile"] = parse_from_header(results.get("from"))

    # message-id host
    results["message_id_host"] = extract_message_id_host(results.get("message_id"))

    # likely origin IP (heuristic)
    results["likely_origin_ip"] = pick_likely_origin_ip(results.get("received_unique_ips", []))

    # extract Authentication-Results or Received-SPF lines if present
    auth = results.get("authentication_results")
    results["auth_summary"] = {}
    if auth:
        results["auth_summary"]["raw"] = auth
        # try to extract dkim=, spf=, dmarc=
        for m in re.finditer(r'(dkim|spf|dmarc)=([^\s;]+)', auth, re.I):
            results["auth_summary"][m.group(1).lower()] = m.group(2)

    # look for tracking pixels in HTML
    results["tracking_pixels"] = detect_tracking_pixels_from_html(body_html)

    # EXIF on saved attachments (if images saved)
    exif_map = []
    for att in attachments:
        path = att.get("saved_to")
        if path and os.path.exists(path) and Image is not None:
            exif = extract_image_exif_from_attachment(path)
            if exif:
                exif_map.append({"filename": att.get("filename"), "exif": exif})
    results["attachments_exif"] = exif_map

    # end user-focused additions

    return results

def print_summary(res: Dict[str, Any]) -> None:
    print("\n==== EMAIL SUMMARY ====")
    print(f"Subject: {res.get('subject')}")
    print(f"From: {res.get('from')}")
    print(f"To: {res.get('to')}")
    print(f"Date: {res.get('date')}")
    print(f"Message-ID: {res.get('message_id')}")
    print(f"Return-Path: {res.get('return_path')}")
    print(f"Top URLs: {res.get('urls')[:10]}")
    print(f"Top URL domains: {res.get('url_domains')[:10]}")
    print(f"Attachments: {[a['filename'] for a in res.get('attachments', [])]}")
    print(f"Received IPs (unique): {res.get('received_unique_ips')}")
    print(f"Indicators: {json.dumps(res.get('indicators', []), indent=2)}")
    print("==== END SUMMARY ====\n")

def main():
    ap = argparse.ArgumentParser(description="Analyze raw email (.eml) for forensic indicators")
    ap.add_argument("eml", help="Path to raw email file (.eml)")
    ap.add_argument("--out", help="Write full JSON result to file")
    ap.add_argument("--save-attachments-dir", default="./eml_attachments", help="Directory to save attachments")
    ap.add_argument("--verify", action="store_true", help="Attempt DKIM/SPF verification using optional libs (dkimpy, pyspf)")
    args = ap.parse_args()

    msg = load_email(args.eml)
    res = gather_mail_analysis(msg, args.save_attachments_dir, do_verify_dkim_spf=args.verify)

    print_summary(res)
    if args.out:
        with open(args.out, "w", encoding="utf-8") as f:
            json.dump(res, f, indent=4, ensure_ascii=False)
        print(f"Wrote JSON to {args.out}")
    else:
        # print compact JSON result to stdout
        print(json.dumps(res, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
