import asyncio
import time
import psutil
import os
import json
from typing import Dict, Any

class TelemetryTracker:
    """
    Tracks compute, inference, and storage metrics for each scan or AI task.
    """

    def __init__(self, db_manager, model_name: str = None):
        self.db = db_manager
        self.model_name = model_name or "unknown_model"

    async def track_scan(self, task_id: str, user_id: str, func, *args, **kwargs) -> Dict[str, Any]:
        """
        Wraps a function (e.g. recon or aggregation) to track telemetry automatically.
        """
        start_time = time.time()
        process = psutil.Process(os.getpid())

        cpu_start = process.cpu_times()
        mem_start = process.memory_info().rss

        # Execute the scan or function
        #result = await func(*args, **kwargs)
        if asyncio.iscoroutinefunction(func):
            result = await func(*args, **kwargs)
        else :
            result = await func(*args,**kwargs)

        cpu_end = process.cpu_times()
        mem_end = process.memory_info().rss
        end_time = time.time()

        duration = round(end_time - start_time, 2)
        summary_text = kwargs.pop("summary_text", "No summary available.")

        telemetry = {
            "task_id": kwargs.get("task_id"),
            "user_id": kwargs.get("user_id", "unknown"),
            "event": "scan_complete",
            "progress": 100,
            "threats_found": kwargs.get("threats_found", 0),
            "risk_level": kwargs.get("risk_level", "Unknown"),
            "duration": duration,
            "summary": summary_text,
            "model_name": self.model_name,
            "runtime_seconds": duration,
            "cpu_seconds": round(cpu_end.user - cpu_start.user, 3),
            "ram_used_mb": round((mem_end - mem_start) / (1024 * 1024), 3),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }


# Approximate storage size of result
        result_size_bytes = len(json.dumps(result).encode("utf-8"))
        telemetry["storage_size_mb"] = round(result_size_bytes / (1024 * 1024), 5)

        # Compute estimated cost (adjust with real pricing later)
        telemetry["cost_estimate_usd"] = round(self.estimate_cost(telemetry), 6)

        # Save to Mongo
        self.db.db.get_collection("telemetry_logs").insert_one(telemetry)

        return {"result": result, "telemetry": telemetry}

    def estimate_cost(self, telemetry: Dict[str, Any]) -> float:
        """
        Rough cost model based on compute + AI + storage.
        """
        compute_cost = telemetry["cpu_seconds"] * 0.000002  # $/CPU-sec
        inference_cost = 0.0005 if "ai" in self.model_name.lower() else 0
        storage_cost = telemetry["storage_size_mb"] * 0.000023
        return compute_cost + inference_cost + storage_cost
