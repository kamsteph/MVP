import logging
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional

from G_L_L.l_region.Aggregation_area import correlator
from Network_Pentest.network.cipr_helper import TargetExpansionError, normalize_targets
from back_end.utils.colored_logger import get_logger
from back_end.database import DatabaseManager
from back_end.event_bus import EventBus
from back_end.mini_transformer.attack_surface_translator import AttackSurfaceTranslator
from back_end.mini_transformer.attack_surfaces import ATTACK_SURFACE_MAP
from back_end.network_cap_matrix import NETWORK_CAPABILITY_MATRIX

# IMPORTANT: import normalize_targets and TargetExpansionError (adjust path if you placed the util elsewhere)

from back_end.pentest_research import PentestResearchRAG

logger = get_logger(__name__, component="ORCHESTRATOR", region="CONTROLLER")
logger.setLevel(logging.DEBUG)

translator = AttackSurfaceTranslator()


class PentestOrchestrator:
    def __init__(self, bus: EventBus, db: DatabaseManager):
        self.bus = bus
        self.db = db
        self.regions = ["network", "web"]
        self.rag = PentestResearchRAG()  # <-- init RAG if available
        self.completed_tasks = []
        logger.info("PentestOrchestrator initialized with regions: %s", self.regions)

    def _expand_full_surfaces(self, raw_attack_surface: List[str]) -> List[str]:
        if any(x in ("full", "all_surfaces") for x in raw_attack_surface):
            try:
                return list(ATTACK_SURFACE_MAP.keys())
            except Exception:
                return [m["attack_surface"] for m in NETWORK_CAPABILITY_MATRIX]
        return raw_attack_surface

    def _expand_aspects_to_surfaces(self, raw_attack_surface: List[str]) -> List[str]:
        aspect_keywords = {"asset_enumeration", "reachability", "deep_scan"}
        if not any(s in aspect_keywords for s in raw_attack_surface):
            return raw_attack_surface

        expanded = []
        for spec in raw_attack_surface:
            if spec in aspect_keywords:
                for m in NETWORK_CAPABILITY_MATRIX:
                    matrix_aspect = m.get("aspect") or None
                    entry_aspects = m.get("aspects", [])
                    if matrix_aspect == spec or spec in entry_aspects:
                        expanded.append(m["attack_surface"])
            else:
                expanded.append(spec)
        seen = set()
        res = []
        for s in expanded:
            if s not in seen:
                seen.add(s)
                res.append(s)
        return res

    def build_tool_jobs(self, scopes: List[Dict[str, Any]], parent_task_id: str, ipv6_enabled: bool = False) -> List[Dict[str, Any]]:
        """
        Matrix-driven job builder.
        For each scope -> selected_area -> create tool jobs using NETWORK_CAPABILITY_MATRIX.
        Each job is a small dict describing a single tool run.
        """
        jobs: List[Dict[str, Any]] = []

        for s in scopes:
            targets = s.get("target", [])
            selected = s.get("selected_areas", [])  # expected list of {category, area} or similar
            adv = s.get("advanced_options", {}) or {}
            tools_override = s.get("tools_by_surface", {}) or {}

            # If user set selected_areas as a flat list of strings, handle that
            normalized_selected = []
            for sa in selected:
                if isinstance(sa, dict):
                    surface_name = sa.get("category") or sa.get("surface") or sa.get("area")
                    if surface_name:
                        normalized_selected.append(surface_name)
                elif isinstance(sa, str):
                    normalized_selected.append(sa)

            if not normalized_selected:
                continue

            for surface_name in normalized_selected:
                matrix_entry = next((m for m in NETWORK_CAPABILITY_MATRIX if m["attack_surface"] == surface_name), None)
                if not matrix_entry:
                    logger.warning("[Orch] No matrix entry for surface '%s' â€” skipping", surface_name)
                    continue

                tools = matrix_entry.get("tools", [])

                override_list = tools_override.get(surface_name, None)
                for t in tools:
                    # t may be dict or string
                    t_name = t["name"] if isinstance(t, dict) else str(t)
                    if override_list is not None and t_name not in override_list:
                        continue

                    # check IPv6 support
                    t_supports_ipv6 = False
                    if isinstance(t, dict):
                        t_supports_ipv6 = t.get("supports_ipv6", False)

                    if ipv6_enabled and not t_supports_ipv6:
                        logger.info(f"[Orch] Skipping tool {t_name} for surface '{surface_name}' (no IPv6 support)")
                        continue

                    job = {
                        "job_id": str(uuid.uuid4()),
                        "parent_task_id": parent_task_id,
                        "targets": targets,
                        "scope": s.get("scope"),
                        "surface": surface_name,
                        "tool": t_name,
                        "role": t.get("role") if isinstance(t, dict) else None,
                        "priority": t.get("priority", 99) if isinstance(t, dict) else 99,
                        "default_ports": t.get("default_ports", matrix_entry.get("default_ports")) if isinstance(t, dict) else matrix_entry.get("default_ports"),
                        "supports_custom_ports": t.get("supports_custom_ports", False) if isinstance(t, dict) else False,
                        "custom_ports": adv.get("custom_ports"),
                        "packet_type": adv.get("packet_type", matrix_entry.get("packet_type")),
                        "advanced_options": adv,
                        "context": {
                            "name": s.get("name"),
                            "description": s.get("description"),
                            "user_scope_index": s.get("index")
                        },
                        "supports_ipv6": t_supports_ipv6
                    }
                    jobs.append(job)

        jobs.sort(key=lambda j: ((j["targets"][0] if j["targets"] else ""), j["priority"]))
        return jobs

    async def submit_scan_request(
            self,
            region: str,
            scan_type: str,
            scope: str,
            target: List[str],
            cross_domain_insight: bool = False,
            **kwargs
    ) -> Dict[str, Any]:
        if region not in self.regions:
            raise ValueError(f"Unknown region: {region}")
        if not target:
            raise ValueError("submit_scan_request requires at least one target")

        # Expand / normalize targets (CIDR/range handling)
        subnetmask_enabled = kwargs.get("subnet_mask", False)
        try:
            explicit_targets, retained_cidrs = normalize_targets(target, subnetmask_enabled=subnetmask_enabled)
        except TargetExpansionError as e:
            raise ValueError(f"Invalid target expansion: {e}")

        # final target list contains explicit expanded IPs + retained CIDR strings
        target = explicit_targets + retained_cidrs
        ipv6_enabled = any(":" in t for t in target)

        # --- Extract flexible parameters ---
        raw_attack_surface: List[str] = kwargs.get("attack_surface", ["full"])
        raw_scopes: Optional[List[Dict[str, Any]]] = kwargs.get("scopes", None)
        advanced_options: Dict[str, Any] = kwargs.get("advanced_options", {}) or {}
        insider_docs: Optional[List[str]] = kwargs.get("insider_docs")
        codebase_docs: Optional[List[str]] = kwargs.get("codebase_docs")

        # Resolve high-level research notes using RAG if available
        research_notes = {"note": "No RAG available."}
        if scope == "white":
            if not codebase_docs:
                raise ValueError("White-box scope requires codebase documents")
            research_notes = self.rag.research(f"Full internal {region} pentest analysis for targets {target}") if self.rag else {"note": "White-box codebase provided, RAG inactive."}
        elif scope == "grey":
            if not insider_docs:
                raise ValueError("Grey-box scope requires at least one insider document")
            research_notes = self.rag.research(f"Partial insider {region} pentest for targets {target}") if self.rag else {"note": "Grey-box mode, no RAG active."}
        else:
            research_notes = {"note": "Black-box minimal reconnaissance."}

        # --- Expand raw_attack_surface shorthand:
        attack_surface_expanded = self._expand_full_surfaces(raw_attack_surface)
        attack_surface_expanded = self._expand_aspects_to_surfaces(attack_surface_expanded)

        # --- Resolve surfaces for enrichment (used for DB/task hints)
        resolved_surface = []
        for surf in attack_surface_expanded:
            # Lookup matrix entry correctly (NETWORK_CAPABILITY_MATRIX is a list)
            try:
                # Try to find matrix definition
                matrix_def = next((m for m in NETWORK_CAPABILITY_MATRIX if m.get("attack_surface") == surf), None)
                definition = matrix_def or {}
                enrichment = self.rag.research(f"Explain risks, common misconfigurations, and known CVEs for {surf}.") if self.rag else {"note": f"No RAG available for {surf}."}
                resolved_surface.append({
                    "surface": surf,
                    "definition": definition,
                    "enrichment": enrichment
                })
            except Exception as e:
                logger.warning(f"Unknown attack surface or lookup error: {surf} -> {e}")

        # --- Build scopes payload: if frontend provided scopes, normalize them; otherwise build a single scope from top-level
        scopes_payload: List[Dict[str, Any]] = []
        # inside submit_scan_request -> scopes_payload section
        if raw_scopes:
            for s in raw_scopes:
                s = s.copy()
                adv_s = s.get("advanced_options", {}) or {}
                s["advanced_options"] = adv_s
                scopes_payload.append(s)
        else:
            scopes_payload.append({
                "scope": scope,
                "target": target,
                "selected_areas": [{"surface": a} for a in attack_surface_expanded],
                "advanced_options": advanced_options
            })

        hints: Dict[str, Any] = {}
        hints["scope"] = scope
        hints["attack_surface"] = resolved_surface
        hints["scopes"] = scopes_payload

        task_id = str(uuid.uuid4())

        #Checks for raw scans
        scan_type_raw = scan_type.lower().strip()
        if scan_type_raw in ("scan only", "scan_only", "scan-only", "vulnerability scan only"):
            canonical_scan_type = "Scan Only"
        elif scan_type_raw in ("scan + attack", "scan_and_attack", "scan+attack", "scan and attack"):
            canonical_scan_type = "Scan + Attack"
        else:
            # fallback if you validated upstream with enum this may be unnecessary
            canonical_scan_type = scan_type_raw

        # decide boolean
        do_exploit = canonical_scan_type == "scan_and_attack"

        # add into hints (so downstream managers know)
        hints["do_exploit"] = do_exploit

        task = {
            "id": task_id,
            "region": region,
            "action": f"initial_{region}_scan",
            "target": target,
            "scan_type": scan_type,
            "scope": scope,
            "research": research_notes,
            "hints": hints,
            "cross_domain_info": {}
        }

        # persist
        self.db.results.insert_one({
            "_id": task_id,
            "task_id": task_id,
            "task": task,
            "status": "queued",
            "created_at": datetime.now()
        })

        if cross_domain_insight:
            events = list(self.db.learning_data.find({}))
            task["cross_domain_info"] = correlator.compute_cross_domain_potential(events)

        logger.info("Submitting scan request to EventBus: %s", task)
        self.bus.publish_task(task)
        self.bus.subscribe("task_completed", self.handle_completed_task)

        # build tool-level jobs and publish them; pass ipv6_enabled so builder can filter tools
        tool_jobs = self.build_tool_jobs(scopes_payload, parent_task_id=task_id, ipv6_enabled=ipv6_enabled)
        logger.debug("Built %d tool jobs for task %s", len(tool_jobs), task_id)

        for job in tool_jobs:
            tool_task = {
                "id": job["job_id"],
                "region": "network",
                "action": "tool_run",
                "hints": job,
                "context": {"parent_task_id": task_id, "submitted_at": datetime.now().isoformat()}
            }
            try:
                self.db.results.insert_one({
                    "_id": tool_task["id"],
                    "task_id": tool_task["id"],
                    "task": tool_task,
                    "status": "queued",
                    "created_at": datetime.now()
                })
            except Exception:
                logger.debug("tool job insert failed (maybe duplicate) for %s", tool_task["id"])

            self.bus.publish_task(tool_task)

        response = {
            "status": "accepted",
            "task_id": task_id,
            "region": region,
            "scope": scope,
            "research": research_notes,
            "message": f"Scan request published with {len(tool_jobs)} tool jobs."
        }
        response.update(task["cross_domain_info"] or {})
        return response

    def handle_completed_task(self, task_result: Dict[str, Any]):
        self.completed_tasks.append(task_result)
        logger.info(f"Received completion signal for task in region '{task_result.get('region')}'.")

#
#
# import logging
# import uuid
# from datetime import datetime
# from typing import Dict, Any, List, Optional
#
# from G_L_L.l_region.Aggregation_area import correlator
# from back_end.utils.colored_logger import get_logger
# from back_end.database import DatabaseManager
# from back_end.event_bus import EventBus
# from back_end.mini_transformer.attack_surface_translator import AttackSurfaceTranslator
# from back_end.mini_transformer.attack_surfaces import ATTACK_SURFACE_MAP
# from back_end.network_cap_matrix import NETWORK_CAPABILITY_MATRIX
#
# from back_end.pentest_research import PentestResearchRAG
#
# logger = get_logger(__name__, component="ORCHESTRATOR", region="CONTROLLER")
# logger.setLevel(logging.DEBUG)
#
# translator = AttackSurfaceTranslator()
#
# class PentestOrchestrator:
#     def __init__(self, bus: EventBus, db: DatabaseManager):
#         self.bus = bus
#         self.db = db
#         self.regions = ["network", "web"]
#         self.rag = PentestResearchRAG()  # <-- init RAG if available
#         self.completed_tasks = []
#         logger.info("PentestOrchestrator initialized with regions: %s", self.regions)
#
#     def _expand_full_surfaces(self, raw_attack_surface: List[str]) -> List[str]:
#         """
#         If frontend used 'full' or 'all_surfaces' shorthand, expand to the canonical list
#         sourced from ATTACK_SURFACE_MAP keys (preferred) or NETWORK_CAPABILITY_MATRIX fallback.
#         """
#         if any(x in ("full", "all_surfaces") for x in raw_attack_surface):
#             try:
#                 return list(ATTACK_SURFACE_MAP.keys())
#             except Exception:
#                 return [m["attack_surface"] for m in NETWORK_CAPABILITY_MATRIX]
#         return raw_attack_surface
#
#     def _expand_aspects_to_surfaces(self, raw_attack_surface: List[str]) -> List[str]:
#         """
#         If user provided aspect keywords (asset_enumeration, reachability, deep_scan),
#         expand those to the surfaces in the matrix that advertise that aspect.
#         (keeps backward compatibility)
#         """
#         aspect_keywords = {"asset_enumeration", "reachability", "deep_scan"}
#         if not any(s in aspect_keywords for s in raw_attack_surface):
#             return raw_attack_surface
#
#         expanded = []
#         for spec in raw_attack_surface:
#             if spec in aspect_keywords:
#                 for m in NETWORK_CAPABILITY_MATRIX:
#                     # allow matrix entries to optionally include 'aspects' list, else 'role' per tool
#                     matrix_aspect = m.get("aspect") or None
#                     entry_aspects = m.get("aspects", [])
#                     if matrix_aspect == spec or spec in entry_aspects:
#                         expanded.append(m["attack_surface"])
#             else:
#                 expanded.append(spec)
#         # unique preserve order
#         seen = set()
#         res = []
#         for s in expanded:
#             if s not in seen:
#                 seen.add(s)
#                 res.append(s)
#         return res
#
#     def build_tool_jobs(self, scopes: List[Dict[str, Any]], parent_task_id: str) -> List[Dict[str, Any]]:
#         """
#         Matrix-driven job builder.
#         For each scope -> selected_area -> create tool jobs using NETWORK_CAPABILITY_MATRIX.
#         Each job is a small dict describing a single tool run.
#         """
#         jobs: List[Dict[str, Any]] = []
#
#         for s in scopes:
#             targets = s.get("target", [])
#             selected = s.get("selected_areas", [])  # expected list of {category, area} or similar
#             adv = s.get("advanced_options", {}) or {}
#             tools_override = s.get("tools_by_surface", {}) or {}
#
#             # If user set selected_areas as a flat list of strings, handle that
#             normalized_selected = []
#             for sa in selected:
#                 if isinstance(sa, dict):
#                     # assume {'category': 'Network', 'area': 'Open ports'} or {'surface':'Open ports'}
#                     surface_name = sa.get("category") or sa.get("surface") or sa.get("area")
#                     if surface_name:
#                         normalized_selected.append(surface_name)
#                 elif isinstance(sa, str):
#                     normalized_selected.append(sa)
#             # if nothing selected and scope provided, default to empty -> skip job generation
#             if not normalized_selected:
#                 continue
#
#             for surface_name in normalized_selected:
#                 matrix_entry = next((m for m in NETWORK_CAPABILITY_MATRIX if m["attack_surface"] == surface_name), None)
#                 if not matrix_entry:
#                     logger.warning("[Orch] No matrix entry for surface '%s' â€” skipping", surface_name)
#                     continue
#
#                 # Per-surface tool list (list of dicts or strings)
#                 tools = matrix_entry.get("tools", [])
#
#                 # If advanced_options.all is True -> include all matrix tools (default behavior)
#                 # If tools_override provided for this surface, only include those specified (in their given order)
#                 override_list = tools_override.get(surface_name, None)
#                 for t in tools:
#                     t_name = t["name"] if isinstance(t, dict) else str(t)
#                     if override_list is not None and t_name not in override_list:
#                         continue
#
#                     # If advanced_options restricts to a subset, your UI can express that too, but by default we include.
#                     job = {
#                         "job_id": str(uuid.uuid4()),
#                         "parent_task_id": parent_task_id,
#                         "targets": targets,
#                         "scope": s.get("scope"),
#                         "surface": surface_name,
#                         "tool": t_name,
#                         "role": t.get("role") if isinstance(t, dict) else None,
#                         "priority": t.get("priority", 99) if isinstance(t, dict) else 99,
#                         "default_ports": t.get("default_ports", matrix_entry.get("default_ports")),
#                         "supports_custom_ports": t.get("supports_custom_ports", False) if isinstance(t, dict) else False,
#                         "custom_ports": adv.get("custom_ports"),
#                         "packet_type": adv.get("packet_type", matrix_entry.get("packet_type")),
#                         "advanced_options": adv,
#                         "context": {
#                             "name": s.get("name"),
#                             "description": s.get("description"),
#                             "user_scope_index": s.get("index")
#                         }
#                     }
#                     jobs.append(job)
#
#         # sort jobs by (first target, priority) to give deterministic ordering
#         jobs.sort(key=lambda j: ((j["targets"][0] if j["targets"] else ""), j["priority"]))
#         return jobs
#
#     async def submit_scan_request(
#             self,
#             region: str,
#             scan_type: str,
#             scope: str,
#             target: List[str],
#             tools: Optional[Dict[str, Any]] = None,
#             cross_domain_insight: bool = False,
#             **kwargs
#     ) -> Dict[str, Any]:
#         """
#         Matrix-driven submission:
#         - Accepts top-level attack_surface or per-card 'scopes' which include 'selected_areas'
#         - Expands 'full' shorthand into all surfaces
#         - Builds tool-level jobs from NETWORK_CAPABILITY_MATRIX and publishes them as 'tool_run' tasks
#         - Stores hints including scopes in DB for traceability and learning
#         """
#         if region not in self.regions:
#             raise ValueError(f"Unknown region: {region}")
#         if not target:
#             raise ValueError("submit_scan_request requires at least one target")
#
#         # --- Extract flexible parameters ---
#         raw_attack_surface: List[str] = kwargs.get("attack_surface", ["full"])
#         raw_scopes: Optional[List[Dict[str, Any]]] = kwargs.get("scopes", None)
#         advanced_options: Dict[str, Any] = kwargs.get("advanced_options", {}) or {}
#         insider_docs: Optional[List[str]] = kwargs.get("insider_docs")
#         codebase_docs: Optional[List[str]] = kwargs.get("codebase_docs")
#         social_media_url: Optional[str] = kwargs.get("social_media_url")
#
#         # Resolve high-level research notes using RAG if available
#         research_notes = {"note": "No RAG available."}
#         if scope == "white":
#             if not codebase_docs:
#                 raise ValueError("White-box scope requires codebase documents")
#             research_notes = self.rag.research(f"Full internal {region} pentest analysis for targets {target}") if self.rag else {"note": "White-box codebase provided, RAG inactive."}
#         elif scope == "grey":
#             if not insider_docs:
#                 raise ValueError("Grey-box scope requires at least one insider document")
#             research_notes = self.rag.research(f"Partial insider {region} pentest for targets {target}") if self.rag else {"note": "Grey-box mode, no RAG active."}
#         else:
#             research_notes = {"note": "Black-box minimal reconnaissance."}
#
#         # --- Expand raw_attack_surface shorthand:
#         attack_surface_expanded = self._expand_full_surfaces(raw_attack_surface)
#         attack_surface_expanded = self._expand_aspects_to_surfaces(attack_surface_expanded)
#
#         # --- Resolve surfaces for enrichment (used for DB/task hints)
#         resolved_surface = []
#         for surf in attack_surface_expanded:
#             try:
#                 definition = self.resolve_attack_surface(surf)
#                 enrichment = self.rag.research(f"Explain risks, common misconfigurations, and known CVEs for {surf}.") if self.rag else {"note": f"No RAG available for {surf}."}
#                 resolved_surface.append({
#                     "surface": surf,
#                     "definition": definition,
#                     "enrichment": enrichment
#                 })
#             except ValueError:
#                 logger.warning(f"Unknown attack surface: {surf}")
#
#         # --- Build scopes payload: if frontend provided scopes, normalize them; otherwise build a single scope from top-level
#         scopes_payload: List[Dict[str, Any]] = []
#         if raw_scopes:
#             # Normalize each scope, set default values & expand per-scope 'all' to advanced flags
#             for s in raw_scopes:
#                 s = s.copy()
#                 adv_s = s.get("advanced_options", {}) or {}
#                 if adv_s.get("all", False):
#                     # set all aspects true (this tells managers to run matrix tool set fully)
#                     adv_s.setdefault("asset_enum", True)
#                     adv_s.setdefault("reachability", True)
#                     adv_s.setdefault("deep_scan", True)
#                 # apply global advanced_options defaults where missing
#                 if advanced_options.get("all", False):
#                     adv_s.setdefault("asset_enum", True)
#                     adv_s.setdefault("reachability", True)
#                     adv_s.setdefault("deep_scan", True)
#                 s["advanced_options"] = adv_s
#                 scopes_payload.append(s)
#         else:
#             scopes_payload.append({
#                 "scope": scope,
#                 "target": target,
#                 "selected_areas": [{"surface": a} for a in attack_surface_expanded],
#                 "advanced_options": advanced_options
#             })
#
#         # Bundle hints for downstream managers
#         hints: Dict[str, Any] = {}
#         hints["scope"] = scope
#         hints["attack_surface"] = resolved_surface
#         hints["scopes"] = scopes_payload
#         hints["tools"] = {"vuln_tools": tools.get("vuln_tools", []) if tools else [], "exploit_tool": tools.get("exploit_tool", "Default") if tools else "Default"}
#
#         # --- Create task record and persist ---
#         task_id = str(uuid.uuid4())
#         task = {
#             "id": task_id,
#             "region": region,
#             "action": f"initial_{region}_scan",
#             "target": target,
#             "scan_type": scan_type,
#             "scope": scope,
#             "research": research_notes,
#             "hints": hints,
#             "cross_domain_info": {}
#         }
#
#         # Save queued task to DB (so we have a top-level record)
#         self.db.results.insert_one({
#             "_id": task_id,
#             "task_id": task_id,
#             "task": task,
#             "status": "queued",
#             "created_at": datetime.now()
#         })
#
#         # Cross-domain enrichment (optional)
#         if cross_domain_insight:
#             events = list(self.db.learning_data.find({}))
#             task["cross_domain_info"] = correlator.compute_cross_domain_potential(events)
#
#         logger.info("Submitting scan request to EventBus: %s", task)
#         # publish top-level task
#         self.bus.publish_task(task)
#         # Subscribe for completion callbacks
#         self.bus.subscribe("task_completed", self.handle_completed_task)
#
#         # --- Build tool-level jobs from the matrix and publish them ---
#         tool_jobs = self.build_tool_jobs(scopes_payload, parent_task_id=task_id)
#         logger.debug("Built %d tool jobs for task %s", len(tool_jobs), task_id)
#
#         for job in tool_jobs:
#             tool_task = {
#                 "id": job["job_id"],
#                 "region": "network",
#                 "action": "tool_run",
#                 "hints": job,
#                 "context": {"parent_task_id": task_id, "submitted_at": datetime.now().isoformat()}
#             }
#             # Persist the job (lightweight record) to DB for traceability
#             try:
#                 self.db.results.insert_one({
#                     "_id": tool_task["id"],
#                     "task_id": tool_task["id"],
#                     "task": tool_task,
#                     "status": "queued",
#                     "created_at": datetime.now()
#                 })
#             except Exception:
#                 logger.debug("tool job insert failed (maybe duplicate) for %s", tool_task["id"])
#
#             self.bus.publish_task(tool_task)
#
#         response = {
#             "status": "accepted",
#             "task_id": task_id,
#             "region": region,
#             "scope": scope,
#             "research": research_notes,
#             "message": f"Scan request published with {len(tool_jobs)} tool jobs."
#         }
#         # also return the number of jobs so UI can show immediate feedback
#         response.update(task["cross_domain_info"] or {})
#         return response
#
#     def handle_completed_task(self, task_result: Dict[str, Any]):
#         """
#         Callback triggered when a manager signals a task is complete.
#         """
#         self.completed_tasks.append(task_result)
#         logger.info(f"Received completion signal for task in region '{task_result.get('region')}'.")
