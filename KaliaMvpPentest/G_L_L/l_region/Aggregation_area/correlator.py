# back_end/validation/hypothesis_generator.py
from typing import List, Dict, Any, Tuple
from collections import defaultdict
import time
import math

# config constants (tweakable)
TIME_WINDOW_SECONDS = 60 * 30  # 30 minutes grouping window
MIN_CONFIDENCE = 0.2           # minimal for published hypothesis
RECENCY_WEIGHT = 0.6           # weight for recent events in confidence
COUNT_WEIGHT = 0.4             # weight for event counts

def _now_ts() -> float:
    return time.time()

def group_by_host_and_artifact(events: List[Dict[str, Any]]) -> Dict[Tuple[str, str], List[Dict[str, Any]]]:
    groups = defaultdict(list)
    now = _now_ts()
    for e in events:
        ip = e.get("ip") or e.get("host") or e.get("target")
        artifact = e.get("artifact_hash") or e.get("credential_hash") or ""
        region = e.get("region", "unknown")  # added from LocalLearner
        severity = e.get("severity", "low")

        # discard stale
        ts = float(e.get("timestamp", now))
        if ts < now - TIME_WINDOW_SECONDS:
            continue

        key = (ip or "unknown", artifact)
        e["region"] = region
        e["severity"] = severity
        groups[key].append(e)
    return groups

def has_event(group: List[Dict[str, Any]], event_type_keyword: str) -> bool:
    for e in group:
        t = e.get("type", "") or e.get("event", "") or e.get("action", "")
        if event_type_keyword.lower() in str(t).lower():
            return True
    return False

def compute_confidence(group: List[Dict[str, Any]]) -> float:
    """
    Simple heuristic: more corroborating events + recency → higher confidence
    Returns value in [0,1].
    """
    if not group:
        return 0.0
    now = _now_ts()
    # recency score: average exponential decay on timestamps
    recencies = []
    for e in group:
        ts = float(e.get("timestamp", now))
        age = max(0.0, now - ts)
        # decay: newer -> closer to 1
        recency_score = math.exp(-age / (60 * 60))  # decay over 1 hour
        recencies.append(recency_score)
    recency_avg = sum(recencies) / len(recencies)
    count_score = min(1.0, len(group) / 5.0)  # saturates at 5 events
    conf = RECENCY_WEIGHT * recency_avg + COUNT_WEIGHT * count_score
    return max(0.0, min(1.0, conf))

def build_template_from_group(group: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Build a minimal honeypot template: services to include and seeded artifacts.
    Keep it conservative: spawn only the necessary services and seed any credentials/artifacts.
    """
    ip = group[0].get("ip") or group[0].get("host") or "0.0.0.0"
    services = set()
    creds = []
    urls = []
    for e in group:
        t = e.get("type", "")
        if "web" in t or "http" in t:
            services.add("http")
            if "url" in e:
                urls.append(e["url"])
        if "ssh" in t or "ssh_auth" in t:
            services.add("ssh")
        if "db" in t or "sql" in t:
            services.add("database")
        if "credential" in e or "credentials" in e or "artifact" in e:
            c = e.get("artifact") or e.get("credential") or {}
            creds.append(c)
    return {
        "target_ip": ip,
        "services": list(services) or ["http"],
        "seed_credentials": creds,
        "seed_urls": urls
    }

def generate_web_steps_from_group(group: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    steps = []
    for e in group:
        t = (e.get("type") or "").lower()
        if "web_rce" in t or "rce" in t:
            # try to reproduce the chain: call the reported payload or a safe variant
            steps.append({
                "kind": "exploit",
                "tool": e.get("exploit_tool") or "web_poc",
                "payload": e.get("payload") or e.get("http_payload") or "",
                "note": "replay or simulated exploit"
            })
        if "sql" in t or "sqli" in t or "sql_injection" in t:
            steps.append({
                "kind": "vuln_scan",
                "tool": "sql_probe",
                "payload": e.get("payload", "")
            })
    # default attempt: trivial probe if no specific step found
    if not steps:
        steps.append({"kind": "probe", "tool": "http_probe", "payload": ""})
    return steps

def generate_net_steps_from_group(group: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    steps = []
    for e in group:
        t = (e.get("type") or "").lower()
        if "portscan" in t or "nmap" in t:
            steps.append({"kind": "portscan", "tool": "nmap", "args": "-sV -p-"})
        if "ssh_auth" in t or "credential" in t:
            creds = e.get("credential") or e.get("artifact") or {}
            steps.append({"kind": "auth_attempt", "tool": "ssh_bruteforce", "creds": creds})
    if not steps:
        steps.append({"kind": "probe", "tool": "tcp_connect", "args": ""})
    return steps

def build_hypotheses(events: List[Dict[str, Any]], min_confidence: float = MIN_CONFIDENCE) -> List[Dict[str, Any]]:
    """
    Main entry. Input: list of normalized events.
    Output: list of hypothesis dicts, ordered by confidence.
    """
    groups = group_by_host_and_artifact(events)
    hypotheses = []
    for key, group in groups.items():
        # rule: look for combination that suggests cross-domain: web_rce + net scan/auth
        has_web_rce = has_event(group, "rce") or has_event(group, "web_rce") or has_event(group, "http_rce")
        has_net = has_event(group, "ssh") or has_event(group, "portscan") or has_event(group, "nmap") or has_event(group, "auth_attempt")
        confidence = compute_confidence(group)
        if has_web_rce and has_net and confidence >= min_confidence:
            hyp = {
                "sandboxable": True,
                "honeypot_template": build_template_from_group(group),
                "web_steps": generate_web_steps_from_group(group),
                "net_steps": generate_net_steps_from_group(group),
                "evidence": group,
                "confidence": confidence,
            }
            hypotheses.append(hyp)
        # optionally produce lower-confidence single-domain hypotheses too
        elif confidence >= (min_confidence * 0.8) and (has_web_rce or has_net):
            # single-domain hypothesis (could be useful for discovery)
            hyp = {
                "sandboxable": False,
                "honeypot_template": build_template_from_group(group),
                "web_steps": generate_web_steps_from_group(group) if has_web_rce else [],
                "net_steps": generate_net_steps_from_group(group) if has_net else [],
                "evidence": group,
                "confidence": confidence * 0.7
            }
            hypotheses.append(hyp)
    # sort by confidence desc
    return sorted(hypotheses, key=lambda h: h["confidence"], reverse=True)

def compute_cross_domain_potential(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Evaluate if events suggest cross-domain potential.
    Returns a dict with score [0..10] and reasons.
    """
    groups = group_by_host_and_artifact(events)
    score = 0.0
    reasons = []

    for key, group in groups.items():
        has_web_rce = has_event(group, "rce") or has_event(group, "web_rce")
        has_net = has_event(group, "ssh") or has_event(group, "portscan") or has_event(group, "auth_attempt")
        confidence = compute_confidence(group)

        if has_web_rce and has_net:
            # scale confidence (0-1) → score (0-10)
            score = max(score, confidence * 10)
            reasons.append(f"Cross-domain risk: web_rce + net activity (conf={confidence:.2f})")

    return {
        "cross_domain_score": round(score, 2),
        "cross_domain_reasons": reasons
    }

