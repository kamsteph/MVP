# -- additions / replacements for web_osint.py --

import requests
import socket
import dns.resolver
import dns.reversename
import shodan
from urllib.parse import urlparse
import os
import logging
from dotenv import load_dotenv

from back_end.utils.colored_logger import get_logger

logger = get_logger(__name__, component="OSINT", region="WEB")
logger.setLevel(logging.DEBUG)

load_dotenv()
SHODAN_API_KEY = os.getenv("SHODAN_API_KEY", "dIhYRp1lzsuNFcskwa8tQwIWZ0mRDf8b")


def dns_lookup(domain):
    results = {}
    try:
        logger.debug("Performing DNS lookup for domain: %s", domain)
        results['A'] = [r.address for r in dns.resolver.resolve(domain, 'A')]
        # MX/NS may not exist for subdomains like 'www'
        try:
            results['MX'] = [str(r.exchange) for r in dns.resolver.resolve(domain, 'MX')]
        except Exception as e_mx:
            logger.debug("MX lookup empty/failed for %s: %s", domain, e_mx)
            results['MX'] = []
        try:
            results['NS'] = [str(r.target) for r in dns.resolver.resolve(domain, 'NS')]
        except Exception as e_ns:
            logger.debug("NS lookup empty/failed for %s: %s", domain, e_ns)
            results['NS'] = []
        logger.info("DNS lookup finished for domain=%s", domain)
    except Exception as e:
        logger.error("DNS lookup failed for %s: %s", domain, e)
        results['error'] = str(e)
    return results


def reverse_dns(ip):
    """Attempt PTR lookup for an IP (returns list or empty)."""
    try:
        reverse_name = dns.reversename.from_address(ip)
        answers = dns.resolver.resolve(reverse_name, 'PTR')
        ptrs = [str(r) for r in answers]
        logger.debug("Reverse DNS PTR for %s: %s", ip, ptrs)
        return ptrs
    except Exception as e:
        logger.debug("Reverse DNS failed for %s: %s", ip, e)
        return []


def ip_rdap(ip):
    """Perform RDAP lookup via rdap.org (returns JSON or error)."""
    try:
        url = f"https://rdap.org/ip/{ip}"
        logger.debug("Querying RDAP for IP %s", ip)
        r = requests.get(url, timeout=6)
        r.raise_for_status()
        data = r.json()
        # extract compact useful fields
        rdap_info = {
            "handle": data.get("handle"),
            "name": data.get("name"),
            "type": data.get("type"),
            "country": data.get("country"),
            "asn": data.get("asn"),
            "entities": data.get("entities", []),
            "network": data.get("network", {})
        }
        logger.info("RDAP lookup successful for IP=%s", ip)
        return rdap_info
    except Exception as e:
        logger.debug("RDAP lookup failed for %s: %s", ip, e)
        return {"error": str(e)}


def shodan_lookup(ip):
    results = {}
    if not SHODAN_API_KEY:
        logger.warning("SHODAN_API_KEY not set - skipping Shodan lookup")
        return {"error": "SHODAN_API_KEY not set"}
    try:
        logger.debug("Performing Shodan lookup for IP: %s", ip)
        api = shodan.Shodan(SHODAN_API_KEY)
        host = api.host(ip)
        # include more fields from Shodan host
        results = {
            "ip": host.get("ip_str", ip),
            "org": host.get("org", "n/a"),
            "asn": host.get("asn", "n/a"),
            "hostnames": host.get("hostnames", []),
            "isp": host.get("isp", "n/a"),
            "city": host.get("city", None),
            "country_name": host.get("country_name", None),
            "os": host.get("os", None),
            "ports": host.get("ports", []),
            "vulns": host.get("vulns", []),
            # optionally keep raw banner entries if you want more detail:
            # "data": host.get("data", [])
        }
        logger.info("Shodan lookup successful for IP=%s", ip)
    except Exception as e:
        logger.error("Shodan lookup failed for IP=%s: %s", ip, e)
        results["error"] = str(e)
    return results


def gather_main_osint_info(url):
    logger.info("[OSINT] Gathering headers/DNS/Shodan for: %s", url)
    try:
        headers = requests.get(url, timeout=5).headers
        logger.debug("Fetched HTTP headers for %s", url)
    except Exception as e:
        logger.error("Failed to fetch headers for %s: %s", url, e)
        headers = {}

    parsed_url = urlparse(url)
    domain = parsed_url.netloc

    dns_info = dns_lookup(domain)

    # Resolve IP from domain
    try:
        ip = socket.gethostbyname(domain)
        logger.debug("Resolved domain %s to IP %s", domain, ip)
    except Exception as e:
        logger.error("Failed to resolve domain %s to IP: %s", domain, e)
        ip = None

    # Reverse DNS (PTR)
    ptrs = reverse_dns(ip) if ip else []

    # RDAP (IP whois)
    rdap_info = ip_rdap(ip) if ip else {"error": "IP resolution failed"}

    # Shodan lookup
    shodan_info = shodan_lookup(ip) if ip else {"error": "IP resolution failed"}

    return {
        "headers": dict(headers),
        "dns": dns_info,
        "ip": ip,
        "reverse_dns": ptrs,
        "rdap": rdap_info,
        "shodan": shodan_info
    }

# --- SOCIAL MEDIA OSINT ---
def gather_social_osint_info(social_urls):
    """
    Simple social media check: try to GET each URL and return status code or 'unreachable'.
    """
    results = []
    for url in social_urls:
        logger.info("[SOCIAL-OSINT] Checking: %s", url)
        try:
            response = requests.get(url, timeout=5)
            logger.debug("Social URL %s responded with status %s", url, response.status_code)
            results.append((url, response.status_code))
        except Exception as e:
            logger.warning("Social URL %s unreachable: %s", url, e)
            results.append((url, 'unreachable'))
    return results




# -------- Email OSINT helpers (paste into web_osint.py) --------
import re
from urllib.parse import urlparse

# reuse existing functions: dns_lookup, reverse_dns, ip_rdap, shodan_lookup
# (make sure they are defined above in the file)

def get_txt_records(domain: str) -> list:
    """Return TXT records for the domain (SPF, DKIM selectors, DMARC)."""
    try:
        answers = dns.resolver.resolve(domain, 'TXT')
        return [''.join(r.strings) if hasattr(r, 'strings') else str(r) for r in answers]
    except Exception as e:
        logger.debug("TXT lookup failed for %s: %s", domain, e)
        return []

def parse_spf(txt_records: list) -> str:
    """Return SPF record string if present, otherwise empty."""
    for txt in txt_records:
        if txt.lower().startswith('v=spf1'):
            return txt
    return ""

def get_dmarc(domain: str) -> str:
    """Fetch DMARC TXT under _dmarc.domain."""
    try:
        answers = dns.resolver.resolve(f"_dmarc.{domain}", 'TXT')
        recs = [''.join(r.strings) if hasattr(r, 'strings') else str(r) for r in answers]
        return recs[0] if recs else ""
    except Exception as e:
        logger.debug("DMARC lookup failed for %s: %s", domain, e)
        return ""

def list_mx_hosts(domain: str) -> list:
    """Return list of (preference, host) tuples for MX records on domain."""
    try:
        answers = dns.resolver.resolve(domain, 'MX')
        mx = sorted([(r.preference, str(r.exchange).rstrip('.')) for r in answers], key=lambda x: x[0])
        return mx
    except Exception as e:
        logger.debug("MX lookup failed for %s: %s", domain, e)
        return []

def resolve_host_to_ips(host: str) -> list:
    """Resolve host to A/AAAA addresses (may return multiple)."""
    ips = []
    try:
        a = dns.resolver.resolve(host, 'A')
        ips += [r.address for r in a]
    except Exception:
        pass
    try:
        aaaa = dns.resolver.resolve(host, 'AAAA')
        ips += [r.address for r in aaaa]
    except Exception:
        pass
    return ips

def gather_email_osint(email_address: str) -> dict:
    """
    High-level email OSINT for an email address.
    Returns:
      - domain
      - MX list (preference, host)
      - MX hosts resolved IPs
      - For each IP: reverse_dns, rdap, shodan
      - SPF record, DMARC policy, all TXT records
    """
    results = {}
    # basic validation
    m = re.match(r"[^@]+@([^@]+\.[^@]+)$", email_address)
    if not m:
        return {"error": "invalid email address format"}

    domain = m.group(1).lower()
    results['email'] = email_address
    results['domain'] = domain

    # MX records
    mx = list_mx_hosts(domain)
    results['mx'] = [{"pref": p, "host": h} for p, h in mx]

    # TXT/SPF/DMARC
    txts = get_txt_records(domain)
    results['txt'] = txts
    results['spf'] = parse_spf(txts)
    results['dmarc'] = get_dmarc(domain)

    # For each MX host, resolve IPs and gather ip-level info
    mx_details = []
    for pref, host in mx:
        entry = {"host": host, "pref": pref}
        ips = resolve_host_to_ips(host)
        entry['ips'] = ips
        ip_infos = []
        for ip in ips:
            info = {"ip": ip}
            # reverse DNS
            info['ptr'] = reverse_dns(ip)
            # rdap
            info['rdap'] = ip_rdap(ip)
            # shodan
            info['shodan'] = shodan_lookup(ip)
            ip_infos.append(info)
        entry['ip_infos'] = ip_infos
        mx_details.append(entry)
    results['mx_details'] = mx_details

    return results

def parse_email_headers(raw_headers: str) -> dict:
    """
    Parse raw email headers (RFC822 style) and extract:
     - From, To, Subject
     - Received headers (list, newest-first), and extract IP addresses from them
    Returns structure with received hops and unique IPs observed.
    """
    lines = raw_headers.splitlines()
    hdrs = {}
    current = None
    for ln in lines:
        if re.match(r'^\S+:\s', ln):
            k, v = ln.split(':', 1)
            current = k.strip()
            hdrs.setdefault(current, "")
            hdrs[current] += v.strip()
        elif current:
            # folded header continuation
            hdrs[current] += " " + ln.strip()

    results = {}
    results['From'] = hdrs.get('From')
    results['To'] = hdrs.get('To')
    results['Subject'] = hdrs.get('Subject')
    # collect Received lines (multiple)
    received = []
    for k, v in hdrs.items():
        if k.lower() == 'received':
            received.append(v)
    results['received_raw'] = received

    # Extract IPv4/IPv6 addresses from Received headers
    ip_pattern = r'(\b(?:\d{1,3}\.){3}\d{1,3}\b|\[[0-9a-fA-F:.]+\])'
    ips = []
    for r in received:
        found = re.findall(ip_pattern, r)
        for f in found:
            # strip brackets for IPv6
            f_clean = f.strip('[]')
            ips.append(f_clean)
    results['received_ips_ordered'] = ips  # order as seen (newest first in header order)
    results['unique_ips'] = list(dict.fromkeys(ips))  # preserve order unique
    return results
# ----------------------------------------------------------------
